{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock Predict multivariable LSTM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/karangautam/Learning-Samples/blob/master/Stock_Predict_multivariable_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "U0qUJL6THabU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGql0bvUHwZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15524a74-405a-4381-f099-4168f835d500"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import datetime\n",
        "import math, time\n",
        "import itertools\n",
        "from sklearn import preprocessing\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aqR8JdxoHzPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "9e66fae2-861e-4b19-e2d2-f8b1673637a1"
      },
      "cell_type": "code",
      "source": [
        "!pip install quandl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting quandl\n",
            "  Downloading https://files.pythonhosted.org/packages/47/8c/b61f5c1e9167f4c1c1c2b86991bbbac51a2bd937b36cbc4cc39248dfb2d1/Quandl-3.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.22.0)\n",
            "Collecting inflection>=0.3.1 (from quandl)\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/35/a6eb45b4e2356fe688b21570864d4aa0d0a880ce387defe9c589112077f8/inflection-0.3.1.tar.gz\n",
            "Collecting more-itertools (from quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/46/886917c6a4ce49dd3fff250c01c5abac5390d57992751384fe61befc4877/more_itertools-4.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.11.0)\n",
            "Collecting pyOpenSSL (from quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.18.4)\n",
            "Collecting ndg-httpsclient (from quandl)\n",
            "  Downloading https://files.pythonhosted.org/packages/78/60/1458ed478eb5777498ca57f4fabf2cf9328ac43e5f6db7839cf73704f3a6/ndg_httpsclient-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.14.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.4)\n",
            "Collecting cryptography>=2.2.1 (from pyOpenSSL->quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/f4/3cde3604972dfa2b0fea85b9711948bb4fb70ab64095322aef35071bd254/cryptography-2.2.2-cp34-abi3-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.2MB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Collecting asn1crypto>=0.21.0 (from cryptography>=2.2.1->pyOpenSSL->quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 20.2MB/s \n",
            "\u001b[?25hCollecting cffi>=1.7; platform_python_implementation != \"PyPy\" (from cryptography>=2.2.1->pyOpenSSL->quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 10.2MB/s \n",
            "\u001b[?25hCollecting pycparser (from cffi>=1.7; platform_python_implementation != \"PyPy\"->cryptography>=2.2.1->pyOpenSSL->quandl)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/2d/aad7f16146f4197a11f8e91fb81df177adcc2073d36a17b1491fd09df6ed/pycparser-2.18.tar.gz (245kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 19.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: inflection, pycparser\n",
            "  Running setup.py bdist_wheel for inflection ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/9f/5a/d3/6fc3bf6516d2a3eb7e18f9f28b472110b59325f3f258fe9211\n",
            "  Running setup.py bdist_wheel for pycparser ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/c0/a1/27/5ba234bd77ea5a290cbf6d675259ec52293193467a12ef1f46\n",
            "Successfully built inflection pycparser\n",
            "Installing collected packages: inflection, more-itertools, asn1crypto, pycparser, cffi, cryptography, pyOpenSSL, ndg-httpsclient, quandl\n",
            "Successfully installed asn1crypto-0.24.0 cffi-1.11.5 cryptography-2.2.2 inflection-0.3.1 more-itertools-4.1.0 ndg-httpsclient-0.5.0 pyOpenSSL-18.0.0 pycparser-2.18 quandl-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdjprYgDH2V0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import quandl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUsrF2xwH70-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e31VMPIQH9yB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRcTcSc3IAJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df= quandl.get(\"NSE/EICHERMOT\", authtoken=\"obPP_aQ1Kb_VcadQf39P\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtFeenXcICmv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQsV1sggIEfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "9744fc89-4118-4f04-dd9d-03e1e763b4e1"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1998-03-24</th>\n",
              "      <td>12.15</td>\n",
              "      <td>12.15</td>\n",
              "      <td>11.3</td>\n",
              "      <td>11.30</td>\n",
              "      <td>11.40</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-03-25</th>\n",
              "      <td>12.00</td>\n",
              "      <td>12.55</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.35</td>\n",
              "      <td>12.35</td>\n",
              "      <td>3500.0</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-03-26</th>\n",
              "      <td>13.50</td>\n",
              "      <td>13.50</td>\n",
              "      <td>12.7</td>\n",
              "      <td>12.75</td>\n",
              "      <td>12.75</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-03-27</th>\n",
              "      <td>12.50</td>\n",
              "      <td>12.80</td>\n",
              "      <td>12.5</td>\n",
              "      <td>12.75</td>\n",
              "      <td>12.75</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-03-30</th>\n",
              "      <td>13.00</td>\n",
              "      <td>13.20</td>\n",
              "      <td>12.5</td>\n",
              "      <td>12.50</td>\n",
              "      <td>12.70</td>\n",
              "      <td>2900.0</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Open   High   Low   Last  Close  Total Trade Quantity  \\\n",
              "Date                                                                 \n",
              "1998-03-24  12.15  12.15  11.3  11.30  11.40                5000.0   \n",
              "1998-03-25  12.00  12.55  12.0  12.35  12.35                3500.0   \n",
              "1998-03-26  13.50  13.50  12.7  12.75  12.75                4500.0   \n",
              "1998-03-27  12.50  12.80  12.5  12.75  12.75                3100.0   \n",
              "1998-03-30  13.00  13.20  12.5  12.50  12.70                2900.0   \n",
              "\n",
              "            Turnover (Lacs)  \n",
              "Date                         \n",
              "1998-03-24             0.58  \n",
              "1998-03-25             0.43  \n",
              "1998-03-26             0.58  \n",
              "1998-03-27             0.40  \n",
              "1998-03-30             0.37  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "fyIcFbA4IGVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values = df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ho_9-W17Iiuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M-I3nV7IlPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# integer encode direction\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# frame as supervised learning\n",
        "reframed = series_to_supervised(scaled, 1, 1)\n",
        "# drop columns we don't want to predict\n",
        "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
        "#print(reframed.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnsC7_2MIn1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2926
        },
        "outputId": "a1f40e19-80ce-4cd1-fd4f-4b6001b21593"
      },
      "cell_type": "code",
      "source": [
        "reframed"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1(t-1)</th>\n",
              "      <th>var2(t-1)</th>\n",
              "      <th>var3(t-1)</th>\n",
              "      <th>var4(t-1)</th>\n",
              "      <th>var5(t-1)</th>\n",
              "      <th>var6(t-1)</th>\n",
              "      <th>var7(t-1)</th>\n",
              "      <th>var1(t)</th>\n",
              "      <th>var2(t)</th>\n",
              "      <th>var3(t)</th>\n",
              "      <th>var4(t)</th>\n",
              "      <th>var5(t)</th>\n",
              "      <th>var6(t)</th>\n",
              "      <th>var7(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>0.002496</td>\n",
              "      <td>2.147534e-06</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.582393e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.582393e-06</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.002245</td>\n",
              "      <td>2.147534e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.002245</td>\n",
              "      <td>2.147534e-06</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.001543</td>\n",
              "      <td>1.469365e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.001543</td>\n",
              "      <td>1.469365e-06</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>1.356337e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>1.356337e-06</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.002496</td>\n",
              "      <td>2.222886e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.002496</td>\n",
              "      <td>2.222886e-06</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>1.017253e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>1.017253e-06</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>6.028166e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>6.028166e-07</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>1.318661e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>1.318661e-06</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.620069e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.620069e-06</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.004402</td>\n",
              "      <td>4.408096e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.004402</td>\n",
              "      <td>4.408096e-06</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>7.648235e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>7.648235e-06</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>0.000259</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.013833</td>\n",
              "      <td>1.627605e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>0.000259</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.013833</td>\n",
              "      <td>1.627605e-05</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>7.911967e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>7.911967e-06</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>1.216936e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000291</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000295</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>1.216936e-05</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.008315</td>\n",
              "      <td>1.036091e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.008315</td>\n",
              "      <td>1.036091e-05</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.004954</td>\n",
              "      <td>5.764433e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.004954</td>\n",
              "      <td>5.764433e-06</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>3.918307e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>3.918307e-06</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.003098</td>\n",
              "      <td>3.353167e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.003098</td>\n",
              "      <td>3.353167e-06</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>1.544717e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000225</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>1.544717e-06</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>1.770774e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.001693</td>\n",
              "      <td>1.770774e-06</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.770774e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.770774e-06</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>1.996830e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>1.996830e-06</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.002596</td>\n",
              "      <td>2.411266e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.002596</td>\n",
              "      <td>2.411266e-06</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>8.665488e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>8.665488e-07</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>8.665488e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>8.665488e-07</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.001041</td>\n",
              "      <td>9.795770e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.001041</td>\n",
              "      <td>9.795770e-07</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>3.466195e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>3.466195e-06</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000991</td>\n",
              "      <td>9.042248e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>0.000991</td>\n",
              "      <td>9.042248e-07</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>1.431689e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>1.431689e-06</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>2.335914e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0.895187</td>\n",
              "      <td>0.895620</td>\n",
              "      <td>0.914724</td>\n",
              "      <td>0.906368</td>\n",
              "      <td>0.906978</td>\n",
              "      <td>0.012349</td>\n",
              "      <td>2.770907e-02</td>\n",
              "      <td>0.892522</td>\n",
              "      <td>0.901113</td>\n",
              "      <td>0.913184</td>\n",
              "      <td>0.908683</td>\n",
              "      <td>0.912039</td>\n",
              "      <td>0.023323</td>\n",
              "      <td>5.255238e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>0.892522</td>\n",
              "      <td>0.901113</td>\n",
              "      <td>0.913184</td>\n",
              "      <td>0.908683</td>\n",
              "      <td>0.912039</td>\n",
              "      <td>0.023323</td>\n",
              "      <td>5.255238e-02</td>\n",
              "      <td>0.898181</td>\n",
              "      <td>0.921129</td>\n",
              "      <td>0.921656</td>\n",
              "      <td>0.932428</td>\n",
              "      <td>0.933743</td>\n",
              "      <td>0.034844</td>\n",
              "      <td>7.995156e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>0.898181</td>\n",
              "      <td>0.921129</td>\n",
              "      <td>0.921656</td>\n",
              "      <td>0.932428</td>\n",
              "      <td>0.933743</td>\n",
              "      <td>0.034844</td>\n",
              "      <td>7.995156e-02</td>\n",
              "      <td>0.914526</td>\n",
              "      <td>0.922922</td>\n",
              "      <td>0.940294</td>\n",
              "      <td>0.933651</td>\n",
              "      <td>0.933635</td>\n",
              "      <td>0.029289</td>\n",
              "      <td>6.760705e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>0.914526</td>\n",
              "      <td>0.922922</td>\n",
              "      <td>0.940294</td>\n",
              "      <td>0.933651</td>\n",
              "      <td>0.933635</td>\n",
              "      <td>0.029289</td>\n",
              "      <td>6.760705e-02</td>\n",
              "      <td>0.918576</td>\n",
              "      <td>0.940847</td>\n",
              "      <td>0.942450</td>\n",
              "      <td>0.958479</td>\n",
              "      <td>0.954072</td>\n",
              "      <td>0.022678</td>\n",
              "      <td>5.309431e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>0.918576</td>\n",
              "      <td>0.940847</td>\n",
              "      <td>0.942450</td>\n",
              "      <td>0.958479</td>\n",
              "      <td>0.954072</td>\n",
              "      <td>0.022678</td>\n",
              "      <td>5.309431e-02</td>\n",
              "      <td>0.940108</td>\n",
              "      <td>0.937859</td>\n",
              "      <td>0.954773</td>\n",
              "      <td>0.952408</td>\n",
              "      <td>0.952436</td>\n",
              "      <td>0.017549</td>\n",
              "      <td>4.112784e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>0.940108</td>\n",
              "      <td>0.937859</td>\n",
              "      <td>0.954773</td>\n",
              "      <td>0.952408</td>\n",
              "      <td>0.952436</td>\n",
              "      <td>0.017549</td>\n",
              "      <td>4.112784e-02</td>\n",
              "      <td>0.937113</td>\n",
              "      <td>0.939897</td>\n",
              "      <td>0.951692</td>\n",
              "      <td>0.944461</td>\n",
              "      <td>0.944167</td>\n",
              "      <td>0.013679</td>\n",
              "      <td>3.209599e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>0.937113</td>\n",
              "      <td>0.939897</td>\n",
              "      <td>0.951692</td>\n",
              "      <td>0.944461</td>\n",
              "      <td>0.944167</td>\n",
              "      <td>0.013679</td>\n",
              "      <td>3.209599e-02</td>\n",
              "      <td>0.929628</td>\n",
              "      <td>0.935985</td>\n",
              "      <td>0.948612</td>\n",
              "      <td>0.940654</td>\n",
              "      <td>0.939489</td>\n",
              "      <td>0.011144</td>\n",
              "      <td>2.602762e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5002</th>\n",
              "      <td>0.929628</td>\n",
              "      <td>0.935985</td>\n",
              "      <td>0.948612</td>\n",
              "      <td>0.940654</td>\n",
              "      <td>0.939489</td>\n",
              "      <td>0.011144</td>\n",
              "      <td>2.602762e-02</td>\n",
              "      <td>0.933519</td>\n",
              "      <td>0.931556</td>\n",
              "      <td>0.941834</td>\n",
              "      <td>0.937916</td>\n",
              "      <td>0.940897</td>\n",
              "      <td>0.013436</td>\n",
              "      <td>3.115827e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5003</th>\n",
              "      <td>0.933519</td>\n",
              "      <td>0.931556</td>\n",
              "      <td>0.941834</td>\n",
              "      <td>0.937916</td>\n",
              "      <td>0.940897</td>\n",
              "      <td>0.013436</td>\n",
              "      <td>3.115827e-02</td>\n",
              "      <td>0.923637</td>\n",
              "      <td>0.932482</td>\n",
              "      <td>0.944841</td>\n",
              "      <td>0.946134</td>\n",
              "      <td>0.947853</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>2.044102e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5004</th>\n",
              "      <td>0.923637</td>\n",
              "      <td>0.932482</td>\n",
              "      <td>0.944841</td>\n",
              "      <td>0.946134</td>\n",
              "      <td>0.947853</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>2.044102e-02</td>\n",
              "      <td>0.940106</td>\n",
              "      <td>0.937858</td>\n",
              "      <td>0.954773</td>\n",
              "      <td>0.945222</td>\n",
              "      <td>0.945312</td>\n",
              "      <td>0.012879</td>\n",
              "      <td>3.016407e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5005</th>\n",
              "      <td>0.940106</td>\n",
              "      <td>0.937858</td>\n",
              "      <td>0.954773</td>\n",
              "      <td>0.945222</td>\n",
              "      <td>0.945312</td>\n",
              "      <td>0.012879</td>\n",
              "      <td>3.016407e-02</td>\n",
              "      <td>0.932621</td>\n",
              "      <td>0.940847</td>\n",
              "      <td>0.953254</td>\n",
              "      <td>0.952865</td>\n",
              "      <td>0.947490</td>\n",
              "      <td>0.015180</td>\n",
              "      <td>3.546520e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5006</th>\n",
              "      <td>0.932621</td>\n",
              "      <td>0.940847</td>\n",
              "      <td>0.953254</td>\n",
              "      <td>0.952865</td>\n",
              "      <td>0.947490</td>\n",
              "      <td>0.015180</td>\n",
              "      <td>3.546520e-02</td>\n",
              "      <td>0.932621</td>\n",
              "      <td>0.931884</td>\n",
              "      <td>0.942672</td>\n",
              "      <td>0.935478</td>\n",
              "      <td>0.935625</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>2.252628e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5007</th>\n",
              "      <td>0.932621</td>\n",
              "      <td>0.931884</td>\n",
              "      <td>0.942672</td>\n",
              "      <td>0.935478</td>\n",
              "      <td>0.935625</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>2.252628e-02</td>\n",
              "      <td>0.920642</td>\n",
              "      <td>0.935350</td>\n",
              "      <td>0.947071</td>\n",
              "      <td>0.950550</td>\n",
              "      <td>0.949573</td>\n",
              "      <td>0.011221</td>\n",
              "      <td>2.622094e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5008</th>\n",
              "      <td>0.920642</td>\n",
              "      <td>0.935350</td>\n",
              "      <td>0.947071</td>\n",
              "      <td>0.950550</td>\n",
              "      <td>0.949573</td>\n",
              "      <td>0.011221</td>\n",
              "      <td>2.622094e-02</td>\n",
              "      <td>0.938311</td>\n",
              "      <td>0.962856</td>\n",
              "      <td>0.962056</td>\n",
              "      <td>0.960446</td>\n",
              "      <td>0.961568</td>\n",
              "      <td>0.022284</td>\n",
              "      <td>5.330496e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5009</th>\n",
              "      <td>0.938311</td>\n",
              "      <td>0.962856</td>\n",
              "      <td>0.962056</td>\n",
              "      <td>0.960446</td>\n",
              "      <td>0.961568</td>\n",
              "      <td>0.022284</td>\n",
              "      <td>5.330496e-02</td>\n",
              "      <td>0.949092</td>\n",
              "      <td>0.952344</td>\n",
              "      <td>0.956142</td>\n",
              "      <td>0.949485</td>\n",
              "      <td>0.949068</td>\n",
              "      <td>0.012854</td>\n",
              "      <td>3.035438e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010</th>\n",
              "      <td>0.949092</td>\n",
              "      <td>0.952344</td>\n",
              "      <td>0.956142</td>\n",
              "      <td>0.949485</td>\n",
              "      <td>0.949068</td>\n",
              "      <td>0.012854</td>\n",
              "      <td>3.035438e-02</td>\n",
              "      <td>0.938580</td>\n",
              "      <td>0.939467</td>\n",
              "      <td>0.932900</td>\n",
              "      <td>0.928505</td>\n",
              "      <td>0.928786</td>\n",
              "      <td>0.029732</td>\n",
              "      <td>6.879497e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5011</th>\n",
              "      <td>0.938580</td>\n",
              "      <td>0.939467</td>\n",
              "      <td>0.932900</td>\n",
              "      <td>0.928505</td>\n",
              "      <td>0.928786</td>\n",
              "      <td>0.029732</td>\n",
              "      <td>6.879497e-02</td>\n",
              "      <td>0.919894</td>\n",
              "      <td>0.917694</td>\n",
              "      <td>0.911705</td>\n",
              "      <td>0.907177</td>\n",
              "      <td>0.909189</td>\n",
              "      <td>0.015937</td>\n",
              "      <td>3.589449e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5012</th>\n",
              "      <td>0.919894</td>\n",
              "      <td>0.917694</td>\n",
              "      <td>0.911705</td>\n",
              "      <td>0.907177</td>\n",
              "      <td>0.909189</td>\n",
              "      <td>0.015937</td>\n",
              "      <td>3.589449e-02</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.899022</td>\n",
              "      <td>0.897781</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.888796</td>\n",
              "      <td>0.012408</td>\n",
              "      <td>2.744601e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5013</th>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.899022</td>\n",
              "      <td>0.897781</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.888796</td>\n",
              "      <td>0.012408</td>\n",
              "      <td>2.744601e-02</td>\n",
              "      <td>0.881710</td>\n",
              "      <td>0.891553</td>\n",
              "      <td>0.896242</td>\n",
              "      <td>0.906703</td>\n",
              "      <td>0.905794</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>3.258514e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5014</th>\n",
              "      <td>0.881710</td>\n",
              "      <td>0.891553</td>\n",
              "      <td>0.896242</td>\n",
              "      <td>0.906703</td>\n",
              "      <td>0.905794</td>\n",
              "      <td>0.014663</td>\n",
              "      <td>3.258514e-02</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.910972</td>\n",
              "      <td>0.917805</td>\n",
              "      <td>0.925430</td>\n",
              "      <td>0.925888</td>\n",
              "      <td>0.019331</td>\n",
              "      <td>4.400440e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5015</th>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.910972</td>\n",
              "      <td>0.917805</td>\n",
              "      <td>0.925430</td>\n",
              "      <td>0.925888</td>\n",
              "      <td>0.019331</td>\n",
              "      <td>4.400440e-02</td>\n",
              "      <td>0.913126</td>\n",
              "      <td>0.918146</td>\n",
              "      <td>0.928587</td>\n",
              "      <td>0.922765</td>\n",
              "      <td>0.922498</td>\n",
              "      <td>0.019176</td>\n",
              "      <td>4.400387e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>0.913126</td>\n",
              "      <td>0.918146</td>\n",
              "      <td>0.928587</td>\n",
              "      <td>0.922765</td>\n",
              "      <td>0.922498</td>\n",
              "      <td>0.019176</td>\n",
              "      <td>4.400387e-02</td>\n",
              "      <td>0.922140</td>\n",
              "      <td>0.932107</td>\n",
              "      <td>0.926280</td>\n",
              "      <td>0.936087</td>\n",
              "      <td>0.932598</td>\n",
              "      <td>0.035160</td>\n",
              "      <td>8.071529e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5017</th>\n",
              "      <td>0.922140</td>\n",
              "      <td>0.932107</td>\n",
              "      <td>0.926280</td>\n",
              "      <td>0.936087</td>\n",
              "      <td>0.932598</td>\n",
              "      <td>0.035160</td>\n",
              "      <td>8.071529e-02</td>\n",
              "      <td>0.920642</td>\n",
              "      <td>0.930391</td>\n",
              "      <td>0.943220</td>\n",
              "      <td>0.940370</td>\n",
              "      <td>0.939462</td>\n",
              "      <td>0.017022</td>\n",
              "      <td>3.952235e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5018</th>\n",
              "      <td>0.920642</td>\n",
              "      <td>0.930391</td>\n",
              "      <td>0.943220</td>\n",
              "      <td>0.940370</td>\n",
              "      <td>0.939462</td>\n",
              "      <td>0.017022</td>\n",
              "      <td>3.952235e-02</td>\n",
              "      <td>0.924854</td>\n",
              "      <td>0.924416</td>\n",
              "      <td>0.935568</td>\n",
              "      <td>0.928332</td>\n",
              "      <td>0.927964</td>\n",
              "      <td>0.011512</td>\n",
              "      <td>2.650724e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5019</th>\n",
              "      <td>0.924854</td>\n",
              "      <td>0.924416</td>\n",
              "      <td>0.935568</td>\n",
              "      <td>0.928332</td>\n",
              "      <td>0.927964</td>\n",
              "      <td>0.011512</td>\n",
              "      <td>2.650724e-02</td>\n",
              "      <td>0.913013</td>\n",
              "      <td>0.925909</td>\n",
              "      <td>0.929824</td>\n",
              "      <td>0.939558</td>\n",
              "      <td>0.936413</td>\n",
              "      <td>0.022376</td>\n",
              "      <td>5.167822e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5020</th>\n",
              "      <td>0.913013</td>\n",
              "      <td>0.925909</td>\n",
              "      <td>0.929824</td>\n",
              "      <td>0.939558</td>\n",
              "      <td>0.936413</td>\n",
              "      <td>0.022376</td>\n",
              "      <td>5.167822e-02</td>\n",
              "      <td>0.913157</td>\n",
              "      <td>0.925025</td>\n",
              "      <td>0.934287</td>\n",
              "      <td>0.930152</td>\n",
              "      <td>0.930108</td>\n",
              "      <td>0.015526</td>\n",
              "      <td>3.578673e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5021</th>\n",
              "      <td>0.913157</td>\n",
              "      <td>0.925025</td>\n",
              "      <td>0.934287</td>\n",
              "      <td>0.930152</td>\n",
              "      <td>0.930108</td>\n",
              "      <td>0.015526</td>\n",
              "      <td>3.578673e-02</td>\n",
              "      <td>0.915156</td>\n",
              "      <td>0.923669</td>\n",
              "      <td>0.935608</td>\n",
              "      <td>0.927561</td>\n",
              "      <td>0.927985</td>\n",
              "      <td>0.013431</td>\n",
              "      <td>3.099747e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5022</th>\n",
              "      <td>0.915156</td>\n",
              "      <td>0.923669</td>\n",
              "      <td>0.935608</td>\n",
              "      <td>0.927561</td>\n",
              "      <td>0.927985</td>\n",
              "      <td>0.013431</td>\n",
              "      <td>3.099747e-02</td>\n",
              "      <td>0.916150</td>\n",
              "      <td>0.918142</td>\n",
              "      <td>0.917548</td>\n",
              "      <td>0.917056</td>\n",
              "      <td>0.915514</td>\n",
              "      <td>0.015493</td>\n",
              "      <td>3.546607e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5023</th>\n",
              "      <td>0.916150</td>\n",
              "      <td>0.918142</td>\n",
              "      <td>0.917548</td>\n",
              "      <td>0.917056</td>\n",
              "      <td>0.915514</td>\n",
              "      <td>0.015493</td>\n",
              "      <td>3.546607e-02</td>\n",
              "      <td>0.895211</td>\n",
              "      <td>0.902003</td>\n",
              "      <td>0.902896</td>\n",
              "      <td>0.897721</td>\n",
              "      <td>0.895629</td>\n",
              "      <td>0.014989</td>\n",
              "      <td>3.352395e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5024</th>\n",
              "      <td>0.895211</td>\n",
              "      <td>0.902003</td>\n",
              "      <td>0.902896</td>\n",
              "      <td>0.897721</td>\n",
              "      <td>0.895629</td>\n",
              "      <td>0.014989</td>\n",
              "      <td>3.352395e-02</td>\n",
              "      <td>0.882909</td>\n",
              "      <td>0.895135</td>\n",
              "      <td>0.908255</td>\n",
              "      <td>0.910290</td>\n",
              "      <td>0.910746</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>2.633736e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5024 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
              "1      0.000139   0.000139   0.000117   0.000116   0.000119   0.002496   \n",
              "2      0.000135   0.000151   0.000139   0.000148   0.000148   0.001743   \n",
              "3      0.000180   0.000179   0.000160   0.000160   0.000160   0.002245   \n",
              "4      0.000150   0.000158   0.000154   0.000160   0.000160   0.001543   \n",
              "5      0.000165   0.000170   0.000154   0.000152   0.000158   0.001442   \n",
              "6      0.000127   0.000143   0.000131   0.000137   0.000137   0.002496   \n",
              "7      0.000142   0.000149   0.000142   0.000146   0.000146   0.001141   \n",
              "8      0.000129   0.000155   0.000132   0.000151   0.000151   0.000690   \n",
              "9      0.000150   0.000161   0.000143   0.000164   0.000158   0.001442   \n",
              "10     0.000145   0.000157   0.000143   0.000160   0.000158   0.001743   \n",
              "11     0.000139   0.000190   0.000143   0.000190   0.000190   0.004402   \n",
              "12     0.000187   0.000229   0.000193   0.000228   0.000231   0.006961   \n",
              "13     0.000240   0.000269   0.000223   0.000259   0.000260   0.013833   \n",
              "14     0.000258   0.000267   0.000231   0.000244   0.000248   0.006760   \n",
              "15     0.000261   0.000291   0.000268   0.000297   0.000295   0.009469   \n",
              "16     0.000326   0.000326   0.000248   0.000266   0.000260   0.008315   \n",
              "17     0.000222   0.000252   0.000228   0.000257   0.000254   0.004954   \n",
              "18     0.000229   0.000239   0.000228   0.000228   0.000228   0.003499   \n",
              "19     0.000232   0.000232   0.000209   0.000222   0.000212   0.003098   \n",
              "20     0.000225   0.000238   0.000205   0.000202   0.000205   0.001392   \n",
              "21     0.000165   0.000206   0.000169   0.000201   0.000196   0.001693   \n",
              "22     0.000172   0.000194   0.000176   0.000198   0.000198   0.001743   \n",
              "23     0.000202   0.000220   0.000180   0.000181   0.000181   0.001894   \n",
              "24     0.000157   0.000167   0.000142   0.000164   0.000157   0.002596   \n",
              "25     0.000153   0.000157   0.000148   0.000146   0.000146   0.000941   \n",
              "26     0.000157   0.000170   0.000152   0.000174   0.000173   0.000941   \n",
              "27     0.000177   0.000178   0.000154   0.000167   0.000167   0.001041   \n",
              "28     0.000163   0.000163   0.000136   0.000155   0.000154   0.003800   \n",
              "29     0.000150   0.000161   0.000148   0.000146   0.000151   0.000991   \n",
              "30     0.000159   0.000175   0.000163   0.000161   0.000161   0.001492   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "4995   0.895187   0.895620   0.914724   0.906368   0.906978   0.012349   \n",
              "4996   0.892522   0.901113   0.913184   0.908683   0.912039   0.023323   \n",
              "4997   0.898181   0.921129   0.921656   0.932428   0.933743   0.034844   \n",
              "4998   0.914526   0.922922   0.940294   0.933651   0.933635   0.029289   \n",
              "4999   0.918576   0.940847   0.942450   0.958479   0.954072   0.022678   \n",
              "5000   0.940108   0.937859   0.954773   0.952408   0.952436   0.017549   \n",
              "5001   0.937113   0.939897   0.951692   0.944461   0.944167   0.013679   \n",
              "5002   0.929628   0.935985   0.948612   0.940654   0.939489   0.011144   \n",
              "5003   0.933519   0.931556   0.941834   0.937916   0.940897   0.013436   \n",
              "5004   0.923637   0.932482   0.944841   0.946134   0.947853   0.008797   \n",
              "5005   0.940106   0.937858   0.954773   0.945222   0.945312   0.012879   \n",
              "5006   0.932621   0.940847   0.953254   0.952865   0.947490   0.015180   \n",
              "5007   0.932621   0.931884   0.942672   0.935478   0.935625   0.009700   \n",
              "5008   0.920642   0.935350   0.947071   0.950550   0.949573   0.011221   \n",
              "5009   0.938311   0.962856   0.962056   0.960446   0.961568   0.022284   \n",
              "5010   0.949092   0.952344   0.956142   0.949485   0.949068   0.012854   \n",
              "5011   0.938580   0.939467   0.932900   0.928505   0.928786   0.029732   \n",
              "5012   0.919894   0.917694   0.911705   0.907177   0.909189   0.015937   \n",
              "5013   0.892193   0.899022   0.897781   0.889807   0.888796   0.012408   \n",
              "5014   0.881710   0.891553   0.896242   0.906703   0.905794   0.014663   \n",
              "5015   0.892193   0.910972   0.917805   0.925430   0.925888   0.019331   \n",
              "5016   0.913126   0.918146   0.928587   0.922765   0.922498   0.019176   \n",
              "5017   0.922140   0.932107   0.926280   0.936087   0.932598   0.035160   \n",
              "5018   0.920642   0.930391   0.943220   0.940370   0.939462   0.017022   \n",
              "5019   0.924854   0.924416   0.935568   0.928332   0.927964   0.011512   \n",
              "5020   0.913013   0.925909   0.929824   0.939558   0.936413   0.022376   \n",
              "5021   0.913157   0.925025   0.934287   0.930152   0.930108   0.015526   \n",
              "5022   0.915156   0.923669   0.935608   0.927561   0.927985   0.013431   \n",
              "5023   0.916150   0.918142   0.917548   0.917056   0.915514   0.015493   \n",
              "5024   0.895211   0.902003   0.902896   0.897721   0.895629   0.014989   \n",
              "\n",
              "         var7(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
              "1     2.147534e-06  0.000135  0.000151  0.000139  0.000148  0.000148   \n",
              "2     1.582393e-06  0.000180  0.000179  0.000160  0.000160  0.000160   \n",
              "3     2.147534e-06  0.000150  0.000158  0.000154  0.000160  0.000160   \n",
              "4     1.469365e-06  0.000165  0.000170  0.000154  0.000152  0.000158   \n",
              "5     1.356337e-06  0.000127  0.000143  0.000131  0.000137  0.000137   \n",
              "6     2.222886e-06  0.000142  0.000149  0.000142  0.000146  0.000146   \n",
              "7     1.017253e-06  0.000129  0.000155  0.000132  0.000151  0.000151   \n",
              "8     6.028166e-07  0.000150  0.000161  0.000143  0.000164  0.000158   \n",
              "9     1.318661e-06  0.000145  0.000157  0.000143  0.000160  0.000158   \n",
              "10    1.620069e-06  0.000139  0.000190  0.000143  0.000190  0.000190   \n",
              "11    4.408096e-06  0.000187  0.000229  0.000193  0.000228  0.000231   \n",
              "12    7.648235e-06  0.000240  0.000269  0.000223  0.000259  0.000260   \n",
              "13    1.627605e-05  0.000258  0.000267  0.000231  0.000244  0.000248   \n",
              "14    7.911967e-06  0.000261  0.000291  0.000268  0.000297  0.000295   \n",
              "15    1.216936e-05  0.000326  0.000326  0.000248  0.000266  0.000260   \n",
              "16    1.036091e-05  0.000222  0.000252  0.000228  0.000257  0.000254   \n",
              "17    5.764433e-06  0.000229  0.000239  0.000228  0.000228  0.000228   \n",
              "18    3.918307e-06  0.000232  0.000232  0.000209  0.000222  0.000212   \n",
              "19    3.353167e-06  0.000225  0.000238  0.000205  0.000202  0.000205   \n",
              "20    1.544717e-06  0.000165  0.000206  0.000169  0.000201  0.000196   \n",
              "21    1.770774e-06  0.000172  0.000194  0.000176  0.000198  0.000198   \n",
              "22    1.770774e-06  0.000202  0.000220  0.000180  0.000181  0.000181   \n",
              "23    1.996830e-06  0.000157  0.000167  0.000142  0.000164  0.000157   \n",
              "24    2.411266e-06  0.000153  0.000157  0.000148  0.000146  0.000146   \n",
              "25    8.665488e-07  0.000157  0.000170  0.000152  0.000174  0.000173   \n",
              "26    8.665488e-07  0.000177  0.000178  0.000154  0.000167  0.000167   \n",
              "27    9.795770e-07  0.000163  0.000163  0.000136  0.000155  0.000154   \n",
              "28    3.466195e-06  0.000150  0.000161  0.000148  0.000146  0.000151   \n",
              "29    9.042248e-07  0.000159  0.000175  0.000163  0.000161  0.000161   \n",
              "30    1.431689e-06  0.000138  0.000179  0.000142  0.000166  0.000166   \n",
              "...            ...       ...       ...       ...       ...       ...   \n",
              "4995  2.770907e-02  0.892522  0.901113  0.913184  0.908683  0.912039   \n",
              "4996  5.255238e-02  0.898181  0.921129  0.921656  0.932428  0.933743   \n",
              "4997  7.995156e-02  0.914526  0.922922  0.940294  0.933651  0.933635   \n",
              "4998  6.760705e-02  0.918576  0.940847  0.942450  0.958479  0.954072   \n",
              "4999  5.309431e-02  0.940108  0.937859  0.954773  0.952408  0.952436   \n",
              "5000  4.112784e-02  0.937113  0.939897  0.951692  0.944461  0.944167   \n",
              "5001  3.209599e-02  0.929628  0.935985  0.948612  0.940654  0.939489   \n",
              "5002  2.602762e-02  0.933519  0.931556  0.941834  0.937916  0.940897   \n",
              "5003  3.115827e-02  0.923637  0.932482  0.944841  0.946134  0.947853   \n",
              "5004  2.044102e-02  0.940106  0.937858  0.954773  0.945222  0.945312   \n",
              "5005  3.016407e-02  0.932621  0.940847  0.953254  0.952865  0.947490   \n",
              "5006  3.546520e-02  0.932621  0.931884  0.942672  0.935478  0.935625   \n",
              "5007  2.252628e-02  0.920642  0.935350  0.947071  0.950550  0.949573   \n",
              "5008  2.622094e-02  0.938311  0.962856  0.962056  0.960446  0.961568   \n",
              "5009  5.330496e-02  0.949092  0.952344  0.956142  0.949485  0.949068   \n",
              "5010  3.035438e-02  0.938580  0.939467  0.932900  0.928505  0.928786   \n",
              "5011  6.879497e-02  0.919894  0.917694  0.911705  0.907177  0.909189   \n",
              "5012  3.589449e-02  0.892193  0.899022  0.897781  0.889807  0.888796   \n",
              "5013  2.744601e-02  0.881710  0.891553  0.896242  0.906703  0.905794   \n",
              "5014  3.258514e-02  0.892193  0.910972  0.917805  0.925430  0.925888   \n",
              "5015  4.400440e-02  0.913126  0.918146  0.928587  0.922765  0.922498   \n",
              "5016  4.400387e-02  0.922140  0.932107  0.926280  0.936087  0.932598   \n",
              "5017  8.071529e-02  0.920642  0.930391  0.943220  0.940370  0.939462   \n",
              "5018  3.952235e-02  0.924854  0.924416  0.935568  0.928332  0.927964   \n",
              "5019  2.650724e-02  0.913013  0.925909  0.929824  0.939558  0.936413   \n",
              "5020  5.167822e-02  0.913157  0.925025  0.934287  0.930152  0.930108   \n",
              "5021  3.578673e-02  0.915156  0.923669  0.935608  0.927561  0.927985   \n",
              "5022  3.099747e-02  0.916150  0.918142  0.917548  0.917056  0.915514   \n",
              "5023  3.546607e-02  0.895211  0.902003  0.902896  0.897721  0.895629   \n",
              "5024  3.352395e-02  0.882909  0.895135  0.908255  0.910290  0.910746   \n",
              "\n",
              "       var6(t)       var7(t)  \n",
              "1     0.001743  1.582393e-06  \n",
              "2     0.002245  2.147534e-06  \n",
              "3     0.001543  1.469365e-06  \n",
              "4     0.001442  1.356337e-06  \n",
              "5     0.002496  2.222886e-06  \n",
              "6     0.001141  1.017253e-06  \n",
              "7     0.000690  6.028166e-07  \n",
              "8     0.001442  1.318661e-06  \n",
              "9     0.001743  1.620069e-06  \n",
              "10    0.004402  4.408096e-06  \n",
              "11    0.006961  7.648235e-06  \n",
              "12    0.013833  1.627605e-05  \n",
              "13    0.006760  7.911967e-06  \n",
              "14    0.009469  1.216936e-05  \n",
              "15    0.008315  1.036091e-05  \n",
              "16    0.004954  5.764433e-06  \n",
              "17    0.003499  3.918307e-06  \n",
              "18    0.003098  3.353167e-06  \n",
              "19    0.001392  1.544717e-06  \n",
              "20    0.001693  1.770774e-06  \n",
              "21    0.001743  1.770774e-06  \n",
              "22    0.001894  1.996830e-06  \n",
              "23    0.002596  2.411266e-06  \n",
              "24    0.000941  8.665488e-07  \n",
              "25    0.000941  8.665488e-07  \n",
              "26    0.001041  9.795770e-07  \n",
              "27    0.003800  3.466195e-06  \n",
              "28    0.000991  9.042248e-07  \n",
              "29    0.001492  1.431689e-06  \n",
              "30    0.002395  2.335914e-06  \n",
              "...        ...           ...  \n",
              "4995  0.023323  5.255238e-02  \n",
              "4996  0.034844  7.995156e-02  \n",
              "4997  0.029289  6.760705e-02  \n",
              "4998  0.022678  5.309431e-02  \n",
              "4999  0.017549  4.112784e-02  \n",
              "5000  0.013679  3.209599e-02  \n",
              "5001  0.011144  2.602762e-02  \n",
              "5002  0.013436  3.115827e-02  \n",
              "5003  0.008797  2.044102e-02  \n",
              "5004  0.012879  3.016407e-02  \n",
              "5005  0.015180  3.546520e-02  \n",
              "5006  0.009700  2.252628e-02  \n",
              "5007  0.011221  2.622094e-02  \n",
              "5008  0.022284  5.330496e-02  \n",
              "5009  0.012854  3.035438e-02  \n",
              "5010  0.029732  6.879497e-02  \n",
              "5011  0.015937  3.589449e-02  \n",
              "5012  0.012408  2.744601e-02  \n",
              "5013  0.014663  3.258514e-02  \n",
              "5014  0.019331  4.400440e-02  \n",
              "5015  0.019176  4.400387e-02  \n",
              "5016  0.035160  8.071529e-02  \n",
              "5017  0.017022  3.952235e-02  \n",
              "5018  0.011512  2.650724e-02  \n",
              "5019  0.022376  5.167822e-02  \n",
              "5020  0.015526  3.578673e-02  \n",
              "5021  0.013431  3.099747e-02  \n",
              "5022  0.015493  3.546607e-02  \n",
              "5023  0.014989  3.352395e-02  \n",
              "5024  0.011729  2.633736e-02  \n",
              "\n",
              "[5024 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "NUnGXiqxIql6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a2f3e8ca-279e-4d97-ec0a-6ce0c9e2685c"
      },
      "cell_type": "code",
      "source": [
        "reframed.drop(reframed.columns[[7,8,9,10,12,13]], axis=1, inplace=True)\n",
        "print(reframed.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
            "1   0.000139   0.000139   0.000117   0.000116   0.000119   0.002496   \n",
            "2   0.000135   0.000151   0.000139   0.000148   0.000148   0.001743   \n",
            "3   0.000180   0.000179   0.000160   0.000160   0.000160   0.002245   \n",
            "4   0.000150   0.000158   0.000154   0.000160   0.000160   0.001543   \n",
            "5   0.000165   0.000170   0.000154   0.000152   0.000158   0.001442   \n",
            "\n",
            "   var7(t-1)   var5(t)  \n",
            "1   0.000002  0.000148  \n",
            "2   0.000002  0.000160  \n",
            "3   0.000002  0.000160  \n",
            "4   0.000001  0.000158  \n",
            "5   0.000001  0.000137  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NHGspEg3IuHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values=reframed.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMR1XglAIxpl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length= int(values.shape[0]*0.90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmX1Sy23IzxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = values[:length, :]\n",
        "test = values[length:, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lw-pyEnlI1wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e6e2485-9858-4a3f-c643-0bdcf8e43743"
      },
      "cell_type": "code",
      "source": [
        "# split into input and outputs\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4521, 1, 7) (4521,) (503, 1, 7) (503,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cIMcCHf4I4ZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam',metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIXCdLdkI7E2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b18d0c83-1df9-430d-9093-f75ccd3b7a38"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 512)               1064960   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,590,785\n",
            "Trainable params: 1,590,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T9Wnvn39I9iD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33882
        },
        "outputId": "9dfdbd81-fbd5-4eb5-c403-349964880bad"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_X, train_y, epochs=1000, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4521 samples, validate on 503 samples\n",
            "Epoch 1/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0336 - val_mean_absolute_error: 0.0336\n",
            "Epoch 2/1000\n",
            " - 2s - loss: 0.0220 - mean_absolute_error: 0.0220 - val_loss: 0.2101 - val_mean_absolute_error: 0.2101\n",
            "Epoch 3/1000\n",
            " - 2s - loss: 0.0272 - mean_absolute_error: 0.0272 - val_loss: 0.0376 - val_mean_absolute_error: 0.0376\n",
            "Epoch 4/1000\n",
            " - 1s - loss: 0.0238 - mean_absolute_error: 0.0238 - val_loss: 0.1786 - val_mean_absolute_error: 0.1786\n",
            "Epoch 5/1000\n",
            " - 2s - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0490 - val_mean_absolute_error: 0.0490\n",
            "Epoch 6/1000\n",
            " - 1s - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.1984 - val_mean_absolute_error: 0.1984\n",
            "Epoch 7/1000\n",
            " - 2s - loss: 0.0147 - mean_absolute_error: 0.0147 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
            "Epoch 8/1000\n",
            " - 2s - loss: 0.0212 - mean_absolute_error: 0.0212 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 9/1000\n",
            " - 1s - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 10/1000\n",
            " - 1s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.1436 - val_mean_absolute_error: 0.1436\n",
            "Epoch 11/1000\n",
            " - 1s - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0107 - val_mean_absolute_error: 0.0107\n",
            "Epoch 12/1000\n",
            " - 2s - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
            "Epoch 13/1000\n",
            " - 2s - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
            "Epoch 14/1000\n",
            " - 1s - loss: 0.0224 - mean_absolute_error: 0.0224 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
            "Epoch 15/1000\n",
            " - 1s - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
            "Epoch 16/1000\n",
            " - 1s - loss: 0.0207 - mean_absolute_error: 0.0207 - val_loss: 0.1012 - val_mean_absolute_error: 0.1012\n",
            "Epoch 17/1000\n",
            " - 1s - loss: 0.0291 - mean_absolute_error: 0.0291 - val_loss: 0.1462 - val_mean_absolute_error: 0.1462\n",
            "Epoch 18/1000\n",
            " - 2s - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
            "Epoch 19/1000\n",
            " - 2s - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
            "Epoch 20/1000\n",
            " - 2s - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 21/1000\n",
            " - 2s - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
            "Epoch 22/1000\n",
            " - 2s - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
            "Epoch 23/1000\n",
            " - 1s - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0454 - val_mean_absolute_error: 0.0454\n",
            "Epoch 24/1000\n",
            " - 1s - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
            "Epoch 25/1000\n",
            " - 1s - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
            "Epoch 26/1000\n",
            " - 1s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
            "Epoch 27/1000\n",
            " - 1s - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
            "Epoch 28/1000\n",
            " - 2s - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0178 - val_mean_absolute_error: 0.0178\n",
            "Epoch 29/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0431 - mean_absolute_error: 0.0431 - val_loss: 0.0581 - val_mean_absolute_error: 0.0581\n",
            "Epoch 30/1000\n",
            " - 2s - loss: 0.0328 - mean_absolute_error: 0.0328 - val_loss: 0.0996 - val_mean_absolute_error: 0.0996\n",
            "Epoch 31/1000\n",
            " - 2s - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0812 - val_mean_absolute_error: 0.0812\n",
            "Epoch 32/1000\n",
            " - 1s - loss: 0.0240 - mean_absolute_error: 0.0240 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
            "Epoch 33/1000\n",
            " - 2s - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
            "Epoch 34/1000\n",
            " - 2s - loss: 0.0146 - mean_absolute_error: 0.0146 - val_loss: 0.0978 - val_mean_absolute_error: 0.0978\n",
            "Epoch 35/1000\n",
            " - 2s - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
            "Epoch 36/1000\n",
            " - 1s - loss: 0.0251 - mean_absolute_error: 0.0251 - val_loss: 0.0990 - val_mean_absolute_error: 0.0990\n",
            "Epoch 37/1000\n",
            " - 1s - loss: 0.0227 - mean_absolute_error: 0.0227 - val_loss: 0.1326 - val_mean_absolute_error: 0.1326\n",
            "Epoch 38/1000\n",
            " - 1s - loss: 0.0223 - mean_absolute_error: 0.0223 - val_loss: 0.0807 - val_mean_absolute_error: 0.0807\n",
            "Epoch 39/1000\n",
            " - 1s - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.1570 - val_mean_absolute_error: 0.1570\n",
            "Epoch 40/1000\n",
            " - 2s - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0708 - val_mean_absolute_error: 0.0708\n",
            "Epoch 41/1000\n",
            " - 2s - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.1204 - val_mean_absolute_error: 0.1204\n",
            "Epoch 42/1000\n",
            " - 1s - loss: 0.0210 - mean_absolute_error: 0.0210 - val_loss: 0.1464 - val_mean_absolute_error: 0.1464\n",
            "Epoch 43/1000\n",
            " - 2s - loss: 0.0251 - mean_absolute_error: 0.0251 - val_loss: 0.0975 - val_mean_absolute_error: 0.0975\n",
            "Epoch 44/1000\n",
            " - 1s - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.1111 - val_mean_absolute_error: 0.1111\n",
            "Epoch 45/1000\n",
            " - 1s - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 46/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0867 - val_mean_absolute_error: 0.0867\n",
            "Epoch 47/1000\n",
            " - 1s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0935 - val_mean_absolute_error: 0.0935\n",
            "Epoch 48/1000\n",
            " - 1s - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0846 - val_mean_absolute_error: 0.0846\n",
            "Epoch 49/1000\n",
            " - 2s - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0805 - val_mean_absolute_error: 0.0805\n",
            "Epoch 50/1000\n",
            " - 1s - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.1362 - val_mean_absolute_error: 0.1362\n",
            "Epoch 51/1000\n",
            " - 1s - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0943 - val_mean_absolute_error: 0.0943\n",
            "Epoch 52/1000\n",
            " - 2s - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592\n",
            "Epoch 53/1000\n",
            " - 2s - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0535 - val_mean_absolute_error: 0.0535\n",
            "Epoch 54/1000\n",
            " - 2s - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0443 - val_mean_absolute_error: 0.0443\n",
            "Epoch 55/1000\n",
            " - 1s - loss: 0.0288 - mean_absolute_error: 0.0288 - val_loss: 0.0387 - val_mean_absolute_error: 0.0387\n",
            "Epoch 56/1000\n",
            " - 1s - loss: 0.0235 - mean_absolute_error: 0.0235 - val_loss: 0.0751 - val_mean_absolute_error: 0.0751\n",
            "Epoch 57/1000\n",
            " - 1s - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 58/1000\n",
            " - 2s - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 59/1000\n",
            " - 1s - loss: 0.0292 - mean_absolute_error: 0.0292 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
            "Epoch 60/1000\n",
            " - 1s - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0460 - val_mean_absolute_error: 0.0460\n",
            "Epoch 61/1000\n",
            " - 1s - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0581 - val_mean_absolute_error: 0.0581\n",
            "Epoch 62/1000\n",
            " - 2s - loss: 0.0231 - mean_absolute_error: 0.0231 - val_loss: 0.1330 - val_mean_absolute_error: 0.1330\n",
            "Epoch 63/1000\n",
            " - 1s - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0820 - val_mean_absolute_error: 0.0820\n",
            "Epoch 64/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0523 - val_mean_absolute_error: 0.0523\n",
            "Epoch 65/1000\n",
            " - 2s - loss: 0.0236 - mean_absolute_error: 0.0236 - val_loss: 0.0811 - val_mean_absolute_error: 0.0811\n",
            "Epoch 66/1000\n",
            " - 1s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0495 - val_mean_absolute_error: 0.0495\n",
            "Epoch 67/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0962 - val_mean_absolute_error: 0.0962\n",
            "Epoch 68/1000\n",
            " - 2s - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
            "Epoch 69/1000\n",
            " - 1s - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
            "Epoch 70/1000\n",
            " - 2s - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
            "Epoch 71/1000\n",
            " - 2s - loss: 0.0137 - mean_absolute_error: 0.0137 - val_loss: 0.0633 - val_mean_absolute_error: 0.0633\n",
            "Epoch 72/1000\n",
            " - 1s - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0474 - val_mean_absolute_error: 0.0474\n",
            "Epoch 73/1000\n",
            " - 2s - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0440 - val_mean_absolute_error: 0.0440\n",
            "Epoch 74/1000\n",
            " - 2s - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0400 - val_mean_absolute_error: 0.0400\n",
            "Epoch 75/1000\n",
            " - 1s - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0603 - val_mean_absolute_error: 0.0603\n",
            "Epoch 76/1000\n",
            " - 1s - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0514 - val_mean_absolute_error: 0.0514\n",
            "Epoch 77/1000\n",
            " - 1s - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0695 - val_mean_absolute_error: 0.0695\n",
            "Epoch 78/1000\n",
            " - 2s - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 79/1000\n",
            " - 2s - loss: 0.0156 - mean_absolute_error: 0.0156 - val_loss: 0.1035 - val_mean_absolute_error: 0.1035\n",
            "Epoch 80/1000\n",
            " - 2s - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0816 - val_mean_absolute_error: 0.0816\n",
            "Epoch 81/1000\n",
            " - 2s - loss: 0.0114 - mean_absolute_error: 0.0114 - val_loss: 0.0884 - val_mean_absolute_error: 0.0884\n",
            "Epoch 82/1000\n",
            " - 1s - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0802 - val_mean_absolute_error: 0.0802\n",
            "Epoch 83/1000\n",
            " - 2s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
            "Epoch 84/1000\n",
            " - 1s - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
            "Epoch 85/1000\n",
            " - 2s - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
            "Epoch 86/1000\n",
            " - 2s - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0986 - val_mean_absolute_error: 0.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 87/1000\n",
            " - 2s - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0573 - val_mean_absolute_error: 0.0573\n",
            "Epoch 88/1000\n",
            " - 2s - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0610 - val_mean_absolute_error: 0.0610\n",
            "Epoch 89/1000\n",
            " - 1s - loss: 0.0115 - mean_absolute_error: 0.0115 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n",
            "Epoch 90/1000\n",
            " - 2s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0626 - val_mean_absolute_error: 0.0626\n",
            "Epoch 91/1000\n",
            " - 2s - loss: 0.0153 - mean_absolute_error: 0.0153 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 92/1000\n",
            " - 2s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0342 - val_mean_absolute_error: 0.0342\n",
            "Epoch 93/1000\n",
            " - 1s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0780 - val_mean_absolute_error: 0.0780\n",
            "Epoch 94/1000\n",
            " - 1s - loss: 0.0263 - mean_absolute_error: 0.0263 - val_loss: 0.0370 - val_mean_absolute_error: 0.0370\n",
            "Epoch 95/1000\n",
            " - 1s - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
            "Epoch 96/1000\n",
            " - 2s - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
            "Epoch 97/1000\n",
            " - 2s - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
            "Epoch 98/1000\n",
            " - 2s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0392 - val_mean_absolute_error: 0.0392\n",
            "Epoch 99/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 100/1000\n",
            " - 1s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
            "Epoch 101/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0583 - val_mean_absolute_error: 0.0583\n",
            "Epoch 102/1000\n",
            " - 2s - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 103/1000\n",
            " - 1s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0401 - val_mean_absolute_error: 0.0401\n",
            "Epoch 104/1000\n",
            " - 2s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
            "Epoch 105/1000\n",
            " - 1s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0646 - val_mean_absolute_error: 0.0646\n",
            "Epoch 106/1000\n",
            " - 1s - loss: 0.0160 - mean_absolute_error: 0.0160 - val_loss: 0.0532 - val_mean_absolute_error: 0.0532\n",
            "Epoch 107/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0405 - val_mean_absolute_error: 0.0405\n",
            "Epoch 108/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
            "Epoch 109/1000\n",
            " - 1s - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
            "Epoch 110/1000\n",
            " - 2s - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
            "Epoch 111/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0600 - val_mean_absolute_error: 0.0600\n",
            "Epoch 112/1000\n",
            " - 2s - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
            "Epoch 113/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
            "Epoch 114/1000\n",
            " - 1s - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
            "Epoch 115/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0369 - val_mean_absolute_error: 0.0369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 116/1000\n",
            " - 2s - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0188 - val_mean_absolute_error: 0.0188\n",
            "Epoch 117/1000\n",
            " - 2s - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0388 - val_mean_absolute_error: 0.0388\n",
            "Epoch 118/1000\n",
            " - 2s - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
            "Epoch 119/1000\n",
            " - 1s - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
            "Epoch 120/1000\n",
            " - 2s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0512 - val_mean_absolute_error: 0.0512\n",
            "Epoch 121/1000\n",
            " - 1s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0398 - val_mean_absolute_error: 0.0398\n",
            "Epoch 122/1000\n",
            " - 1s - loss: 0.0190 - mean_absolute_error: 0.0190 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
            "Epoch 123/1000\n",
            " - 1s - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
            "Epoch 124/1000\n",
            " - 1s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365\n",
            "Epoch 125/1000\n",
            " - 1s - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0432 - val_mean_absolute_error: 0.0432\n",
            "Epoch 126/1000\n",
            " - 1s - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0551 - val_mean_absolute_error: 0.0551\n",
            "Epoch 127/1000\n",
            " - 1s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0474 - val_mean_absolute_error: 0.0474\n",
            "Epoch 128/1000\n",
            " - 1s - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0476 - val_mean_absolute_error: 0.0476\n",
            "Epoch 129/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0541 - val_mean_absolute_error: 0.0541\n",
            "Epoch 130/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
            "Epoch 131/1000\n",
            " - 1s - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0679 - val_mean_absolute_error: 0.0679\n",
            "Epoch 132/1000\n",
            " - 1s - loss: 0.0243 - mean_absolute_error: 0.0243 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
            "Epoch 133/1000\n",
            " - 2s - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359\n",
            "Epoch 134/1000\n",
            " - 2s - loss: 0.0192 - mean_absolute_error: 0.0192 - val_loss: 0.0399 - val_mean_absolute_error: 0.0399\n",
            "Epoch 135/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 136/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0330 - val_mean_absolute_error: 0.0330\n",
            "Epoch 137/1000\n",
            " - 2s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
            "Epoch 138/1000\n",
            " - 2s - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0524 - val_mean_absolute_error: 0.0524\n",
            "Epoch 139/1000\n",
            " - 2s - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
            "Epoch 140/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
            "Epoch 141/1000\n",
            " - 1s - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
            "Epoch 142/1000\n",
            " - 2s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0378 - val_mean_absolute_error: 0.0378\n",
            "Epoch 143/1000\n",
            " - 2s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
            "Epoch 144/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0911 - val_mean_absolute_error: 0.0911\n",
            "Epoch 145/1000\n",
            " - 2s - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
            "Epoch 146/1000\n",
            " - 1s - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0830 - val_mean_absolute_error: 0.0830\n",
            "Epoch 147/1000\n",
            " - 2s - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0370 - val_mean_absolute_error: 0.0370\n",
            "Epoch 148/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0744 - val_mean_absolute_error: 0.0744\n",
            "Epoch 149/1000\n",
            " - 1s - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
            "Epoch 150/1000\n",
            " - 1s - loss: 0.0132 - mean_absolute_error: 0.0132 - val_loss: 0.0391 - val_mean_absolute_error: 0.0391\n",
            "Epoch 151/1000\n",
            " - 1s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0239 - val_mean_absolute_error: 0.0239\n",
            "Epoch 152/1000\n",
            " - 1s - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0219 - val_mean_absolute_error: 0.0219\n",
            "Epoch 153/1000\n",
            " - 1s - loss: 0.0151 - mean_absolute_error: 0.0151 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
            "Epoch 154/1000\n",
            " - 1s - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0997 - val_mean_absolute_error: 0.0997\n",
            "Epoch 155/1000\n",
            " - 2s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0378 - val_mean_absolute_error: 0.0378\n",
            "Epoch 156/1000\n",
            " - 2s - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "Epoch 157/1000\n",
            " - 2s - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0432 - val_mean_absolute_error: 0.0432\n",
            "Epoch 158/1000\n",
            " - 2s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.1100 - val_mean_absolute_error: 0.1100\n",
            "Epoch 159/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0833 - val_mean_absolute_error: 0.0833\n",
            "Epoch 160/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
            "Epoch 161/1000\n",
            " - 2s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
            "Epoch 162/1000\n",
            " - 1s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
            "Epoch 163/1000\n",
            " - 2s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
            "Epoch 164/1000\n",
            " - 2s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0873 - val_mean_absolute_error: 0.0873\n",
            "Epoch 165/1000\n",
            " - 1s - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0235 - val_mean_absolute_error: 0.0235\n",
            "Epoch 166/1000\n",
            " - 1s - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
            "Epoch 167/1000\n",
            " - 1s - loss: 0.0121 - mean_absolute_error: 0.0121 - val_loss: 0.0110 - val_mean_absolute_error: 0.0110\n",
            "Epoch 168/1000\n",
            " - 2s - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0897 - val_mean_absolute_error: 0.0897\n",
            "Epoch 169/1000\n",
            " - 1s - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 170/1000\n",
            " - 2s - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
            "Epoch 171/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
            "Epoch 172/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 173/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
            "Epoch 174/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
            "Epoch 175/1000\n",
            " - 1s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
            "Epoch 176/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
            "Epoch 177/1000\n",
            " - 1s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
            "Epoch 178/1000\n",
            " - 2s - loss: 0.0102 - mean_absolute_error: 0.0102 - val_loss: 0.0669 - val_mean_absolute_error: 0.0669\n",
            "Epoch 179/1000\n",
            " - 1s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0582 - val_mean_absolute_error: 0.0582\n",
            "Epoch 180/1000\n",
            " - 1s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
            "Epoch 181/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
            "Epoch 182/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
            "Epoch 183/1000\n",
            " - 1s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
            "Epoch 184/1000\n",
            " - 1s - loss: 0.0117 - mean_absolute_error: 0.0117 - val_loss: 0.0727 - val_mean_absolute_error: 0.0727\n",
            "Epoch 185/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
            "Epoch 186/1000\n",
            " - 2s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0436 - val_mean_absolute_error: 0.0436\n",
            "Epoch 187/1000\n",
            " - 1s - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
            "Epoch 188/1000\n",
            " - 2s - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0328 - val_mean_absolute_error: 0.0328\n",
            "Epoch 189/1000\n",
            " - 2s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0176 - val_mean_absolute_error: 0.0176\n",
            "Epoch 190/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
            "Epoch 191/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
            "Epoch 192/1000\n",
            " - 2s - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
            "Epoch 193/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
            "Epoch 194/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
            "Epoch 195/1000\n",
            " - 1s - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
            "Epoch 196/1000\n",
            " - 2s - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
            "Epoch 197/1000\n",
            " - 1s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.1007 - val_mean_absolute_error: 0.1007\n",
            "Epoch 198/1000\n",
            " - 2s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0808 - val_mean_absolute_error: 0.0808\n",
            "Epoch 199/1000\n",
            " - 1s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0478 - val_mean_absolute_error: 0.0478\n",
            "Epoch 200/1000\n",
            " - 2s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0560 - val_mean_absolute_error: 0.0560\n",
            "Epoch 201/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
            "Epoch 202/1000\n",
            " - 2s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0185 - val_mean_absolute_error: 0.0185\n",
            "Epoch 203/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0167 - val_mean_absolute_error: 0.0167\n",
            "Epoch 204/1000\n",
            " - 1s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 205/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0477 - val_mean_absolute_error: 0.0477\n",
            "Epoch 206/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0468 - val_mean_absolute_error: 0.0468\n",
            "Epoch 207/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359\n",
            "Epoch 208/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
            "Epoch 209/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "Epoch 210/1000\n",
            " - 1s - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
            "Epoch 211/1000\n",
            " - 1s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
            "Epoch 212/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
            "Epoch 213/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
            "Epoch 214/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0445 - val_mean_absolute_error: 0.0445\n",
            "Epoch 215/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0597 - val_mean_absolute_error: 0.0597\n",
            "Epoch 216/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0381 - val_mean_absolute_error: 0.0381\n",
            "Epoch 217/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0385 - val_mean_absolute_error: 0.0385\n",
            "Epoch 218/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0385 - val_mean_absolute_error: 0.0385\n",
            "Epoch 219/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0258 - val_mean_absolute_error: 0.0258\n",
            "Epoch 220/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
            "Epoch 221/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.1066 - val_mean_absolute_error: 0.1066\n",
            "Epoch 222/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0889 - val_mean_absolute_error: 0.0889\n",
            "Epoch 223/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0450 - val_mean_absolute_error: 0.0450\n",
            "Epoch 224/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0368 - val_mean_absolute_error: 0.0368\n",
            "Epoch 225/1000\n",
            " - 1s - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
            "Epoch 226/1000\n",
            " - 1s - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0427 - val_mean_absolute_error: 0.0427\n",
            "Epoch 227/1000\n",
            " - 2s - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0448 - val_mean_absolute_error: 0.0448\n",
            "Epoch 228/1000\n",
            " - 2s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
            "Epoch 229/1000\n",
            " - 2s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.1010 - val_mean_absolute_error: 0.1010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 230/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 231/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
            "Epoch 232/1000\n",
            " - 2s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
            "Epoch 233/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
            "Epoch 234/1000\n",
            " - 1s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0401 - val_mean_absolute_error: 0.0401\n",
            "Epoch 235/1000\n",
            " - 1s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0551 - val_mean_absolute_error: 0.0551\n",
            "Epoch 236/1000\n",
            " - 2s - loss: 0.0134 - mean_absolute_error: 0.0134 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365\n",
            "Epoch 237/1000\n",
            " - 2s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
            "Epoch 238/1000\n",
            " - 1s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
            "Epoch 239/1000\n",
            " - 1s - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.1055 - val_mean_absolute_error: 0.1055\n",
            "Epoch 240/1000\n",
            " - 1s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0908 - val_mean_absolute_error: 0.0908\n",
            "Epoch 241/1000\n",
            " - 1s - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 242/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
            "Epoch 243/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0376 - val_mean_absolute_error: 0.0376\n",
            "Epoch 244/1000\n",
            " - 1s - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0367 - val_mean_absolute_error: 0.0367\n",
            "Epoch 245/1000\n",
            " - 1s - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359\n",
            "Epoch 246/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
            "Epoch 247/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0392 - val_mean_absolute_error: 0.0392\n",
            "Epoch 248/1000\n",
            " - 2s - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0786 - val_mean_absolute_error: 0.0786\n",
            "Epoch 249/1000\n",
            " - 2s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.1066 - val_mean_absolute_error: 0.1066\n",
            "Epoch 250/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0693 - val_mean_absolute_error: 0.0693\n",
            "Epoch 251/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0382 - val_mean_absolute_error: 0.0382\n",
            "Epoch 252/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n",
            "Epoch 253/1000\n",
            " - 1s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 254/1000\n",
            " - 2s - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0338 - val_mean_absolute_error: 0.0338\n",
            "Epoch 255/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
            "Epoch 256/1000\n",
            " - 2s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
            "Epoch 257/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0476 - val_mean_absolute_error: 0.0476\n",
            "Epoch 258/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
            "Epoch 259/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0608 - val_mean_absolute_error: 0.0608\n",
            "Epoch 260/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
            "Epoch 261/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
            "Epoch 262/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0692 - val_mean_absolute_error: 0.0692\n",
            "Epoch 263/1000\n",
            " - 1s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0445 - val_mean_absolute_error: 0.0445\n",
            "Epoch 264/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 265/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0490 - val_mean_absolute_error: 0.0490\n",
            "Epoch 266/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
            "Epoch 267/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0472 - val_mean_absolute_error: 0.0472\n",
            "Epoch 268/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.1009 - val_mean_absolute_error: 0.1009\n",
            "Epoch 269/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0768 - val_mean_absolute_error: 0.0768\n",
            "Epoch 270/1000\n",
            " - 1s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0543 - val_mean_absolute_error: 0.0543\n",
            "Epoch 271/1000\n",
            " - 2s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0506 - val_mean_absolute_error: 0.0506\n",
            "Epoch 272/1000\n",
            " - 1s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0342 - val_mean_absolute_error: 0.0342\n",
            "Epoch 273/1000\n",
            " - 2s - loss: 0.0126 - mean_absolute_error: 0.0126 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
            "Epoch 274/1000\n",
            " - 1s - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.1102 - val_mean_absolute_error: 0.1102\n",
            "Epoch 275/1000\n",
            " - 2s - loss: 0.0136 - mean_absolute_error: 0.0136 - val_loss: 0.1015 - val_mean_absolute_error: 0.1015\n",
            "Epoch 276/1000\n",
            " - 1s - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0881 - val_mean_absolute_error: 0.0881\n",
            "Epoch 277/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0502 - val_mean_absolute_error: 0.0502\n",
            "Epoch 278/1000\n",
            " - 2s - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
            "Epoch 279/1000\n",
            " - 1s - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
            "Epoch 280/1000\n",
            " - 1s - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0396 - val_mean_absolute_error: 0.0396\n",
            "Epoch 281/1000\n",
            " - 1s - loss: 0.0152 - mean_absolute_error: 0.0152 - val_loss: 0.0950 - val_mean_absolute_error: 0.0950\n",
            "Epoch 282/1000\n",
            " - 1s - loss: 0.0122 - mean_absolute_error: 0.0122 - val_loss: 0.0577 - val_mean_absolute_error: 0.0577\n",
            "Epoch 283/1000\n",
            " - 1s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0335 - val_mean_absolute_error: 0.0335\n",
            "Epoch 284/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
            "Epoch 285/1000\n",
            " - 2s - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
            "Epoch 286/1000\n",
            " - 2s - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0486 - val_mean_absolute_error: 0.0486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 287/1000\n",
            " - 2s - loss: 0.0154 - mean_absolute_error: 0.0154 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
            "Epoch 288/1000\n",
            " - 2s - loss: 0.0152 - mean_absolute_error: 0.0152 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
            "Epoch 289/1000\n",
            " - 2s - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
            "Epoch 290/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
            "Epoch 291/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.1040 - val_mean_absolute_error: 0.1040\n",
            "Epoch 292/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.1047 - val_mean_absolute_error: 0.1047\n",
            "Epoch 293/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
            "Epoch 294/1000\n",
            " - 2s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n",
            "Epoch 295/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
            "Epoch 296/1000\n",
            " - 2s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
            "Epoch 297/1000\n",
            " - 2s - loss: 0.0158 - mean_absolute_error: 0.0158 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 298/1000\n",
            " - 2s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0770 - val_mean_absolute_error: 0.0770\n",
            "Epoch 299/1000\n",
            " - 1s - loss: 0.0216 - mean_absolute_error: 0.0216 - val_loss: 0.0783 - val_mean_absolute_error: 0.0783\n",
            "Epoch 300/1000\n",
            " - 1s - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.0423 - val_mean_absolute_error: 0.0423\n",
            "Epoch 301/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0360 - val_mean_absolute_error: 0.0360\n",
            "Epoch 302/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0308 - val_mean_absolute_error: 0.0308\n",
            "Epoch 303/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
            "Epoch 304/1000\n",
            " - 2s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
            "Epoch 305/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0946 - val_mean_absolute_error: 0.0946\n",
            "Epoch 306/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0983 - val_mean_absolute_error: 0.0983\n",
            "Epoch 307/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0754 - val_mean_absolute_error: 0.0754\n",
            "Epoch 308/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
            "Epoch 309/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
            "Epoch 310/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0576 - val_mean_absolute_error: 0.0576\n",
            "Epoch 311/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
            "Epoch 312/1000\n",
            " - 2s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
            "Epoch 313/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
            "Epoch 314/1000\n",
            " - 2s - loss: 0.0135 - mean_absolute_error: 0.0135 - val_loss: 0.0704 - val_mean_absolute_error: 0.0704\n",
            "Epoch 315/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
            "Epoch 316/1000\n",
            " - 1s - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0899 - val_mean_absolute_error: 0.0899\n",
            "Epoch 317/1000\n",
            " - 2s - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
            "Epoch 318/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0422 - val_mean_absolute_error: 0.0422\n",
            "Epoch 319/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
            "Epoch 320/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0390 - val_mean_absolute_error: 0.0390\n",
            "Epoch 321/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0854 - val_mean_absolute_error: 0.0854\n",
            "Epoch 322/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0855 - val_mean_absolute_error: 0.0855\n",
            "Epoch 323/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 324/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
            "Epoch 325/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0456 - val_mean_absolute_error: 0.0456\n",
            "Epoch 326/1000\n",
            " - 2s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0495 - val_mean_absolute_error: 0.0495\n",
            "Epoch 327/1000\n",
            " - 1s - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
            "Epoch 328/1000\n",
            " - 1s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
            "Epoch 329/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 330/1000\n",
            " - 2s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
            "Epoch 331/1000\n",
            " - 1s - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0404 - val_mean_absolute_error: 0.0404\n",
            "Epoch 332/1000\n",
            " - 1s - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
            "Epoch 333/1000\n",
            " - 1s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0741 - val_mean_absolute_error: 0.0741\n",
            "Epoch 334/1000\n",
            " - 2s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0651 - val_mean_absolute_error: 0.0651\n",
            "Epoch 335/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0665 - val_mean_absolute_error: 0.0665\n",
            "Epoch 336/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0555 - val_mean_absolute_error: 0.0555\n",
            "Epoch 337/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0815 - val_mean_absolute_error: 0.0815\n",
            "Epoch 338/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0516 - val_mean_absolute_error: 0.0516\n",
            "Epoch 339/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0594 - val_mean_absolute_error: 0.0594\n",
            "Epoch 340/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0381 - val_mean_absolute_error: 0.0381\n",
            "Epoch 341/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0467 - val_mean_absolute_error: 0.0467\n",
            "Epoch 342/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0532 - val_mean_absolute_error: 0.0532\n",
            "Epoch 343/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0430 - val_mean_absolute_error: 0.0430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 344/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0416 - val_mean_absolute_error: 0.0416\n",
            "Epoch 345/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0925 - val_mean_absolute_error: 0.0925\n",
            "Epoch 346/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0841 - val_mean_absolute_error: 0.0841\n",
            "Epoch 347/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
            "Epoch 348/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0522 - val_mean_absolute_error: 0.0522\n",
            "Epoch 349/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
            "Epoch 350/1000\n",
            " - 1s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 351/1000\n",
            " - 2s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0265 - val_mean_absolute_error: 0.0265\n",
            "Epoch 352/1000\n",
            " - 1s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
            "Epoch 353/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
            "Epoch 354/1000\n",
            " - 1s - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0863 - val_mean_absolute_error: 0.0863\n",
            "Epoch 355/1000\n",
            " - 1s - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
            "Epoch 356/1000\n",
            " - 2s - loss: 0.0143 - mean_absolute_error: 0.0143 - val_loss: 0.0806 - val_mean_absolute_error: 0.0806\n",
            "Epoch 357/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
            "Epoch 358/1000\n",
            " - 2s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
            "Epoch 359/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0793 - val_mean_absolute_error: 0.0793\n",
            "Epoch 360/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0903 - val_mean_absolute_error: 0.0903\n",
            "Epoch 361/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
            "Epoch 362/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
            "Epoch 363/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0356 - val_mean_absolute_error: 0.0356\n",
            "Epoch 364/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359\n",
            "Epoch 365/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0433 - val_mean_absolute_error: 0.0433\n",
            "Epoch 366/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
            "Epoch 367/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0443 - val_mean_absolute_error: 0.0443\n",
            "Epoch 368/1000\n",
            " - 1s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0370 - val_mean_absolute_error: 0.0370\n",
            "Epoch 369/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0240 - val_mean_absolute_error: 0.0240\n",
            "Epoch 370/1000\n",
            " - 1s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n",
            "Epoch 371/1000\n",
            " - 1s - loss: 0.0120 - mean_absolute_error: 0.0120 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
            "Epoch 372/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0224 - val_mean_absolute_error: 0.0224\n",
            "Epoch 373/1000\n",
            " - 2s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0685 - val_mean_absolute_error: 0.0685\n",
            "Epoch 374/1000\n",
            " - 2s - loss: 0.0112 - mean_absolute_error: 0.0112 - val_loss: 0.0763 - val_mean_absolute_error: 0.0763\n",
            "Epoch 375/1000\n",
            " - 1s - loss: 0.0128 - mean_absolute_error: 0.0128 - val_loss: 0.0755 - val_mean_absolute_error: 0.0755\n",
            "Epoch 376/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0458 - val_mean_absolute_error: 0.0458\n",
            "Epoch 377/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0475 - val_mean_absolute_error: 0.0475\n",
            "Epoch 378/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0527 - val_mean_absolute_error: 0.0527\n",
            "Epoch 379/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0622 - val_mean_absolute_error: 0.0622\n",
            "Epoch 380/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
            "Epoch 381/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0595 - val_mean_absolute_error: 0.0595\n",
            "Epoch 382/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0503 - val_mean_absolute_error: 0.0503\n",
            "Epoch 383/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
            "Epoch 384/1000\n",
            " - 2s - loss: 0.0103 - mean_absolute_error: 0.0103 - val_loss: 0.0287 - val_mean_absolute_error: 0.0287\n",
            "Epoch 385/1000\n",
            " - 2s - loss: 0.0149 - mean_absolute_error: 0.0149 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
            "Epoch 386/1000\n",
            " - 1s - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0849 - val_mean_absolute_error: 0.0849\n",
            "Epoch 387/1000\n",
            " - 2s - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0705 - val_mean_absolute_error: 0.0705\n",
            "Epoch 388/1000\n",
            " - 2s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0451 - val_mean_absolute_error: 0.0451\n",
            "Epoch 389/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0506 - val_mean_absolute_error: 0.0506\n",
            "Epoch 390/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
            "Epoch 391/1000\n",
            " - 1s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0556 - val_mean_absolute_error: 0.0556\n",
            "Epoch 392/1000\n",
            " - 1s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0475 - val_mean_absolute_error: 0.0475\n",
            "Epoch 393/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0449 - val_mean_absolute_error: 0.0449\n",
            "Epoch 394/1000\n",
            " - 1s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 395/1000\n",
            " - 2s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0585 - val_mean_absolute_error: 0.0585\n",
            "Epoch 396/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
            "Epoch 397/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0574 - val_mean_absolute_error: 0.0574\n",
            "Epoch 398/1000\n",
            " - 2s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0472 - val_mean_absolute_error: 0.0472\n",
            "Epoch 399/1000\n",
            " - 1s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
            "Epoch 400/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 401/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
            "Epoch 402/1000\n",
            " - 2s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0857 - val_mean_absolute_error: 0.0857\n",
            "Epoch 403/1000\n",
            " - 1s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
            "Epoch 404/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
            "Epoch 405/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
            "Epoch 406/1000\n",
            " - 2s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0402 - val_mean_absolute_error: 0.0402\n",
            "Epoch 407/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0402 - val_mean_absolute_error: 0.0402\n",
            "Epoch 408/1000\n",
            " - 1s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 409/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0520 - val_mean_absolute_error: 0.0520\n",
            "Epoch 410/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0607 - val_mean_absolute_error: 0.0607\n",
            "Epoch 411/1000\n",
            " - 2s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0516 - val_mean_absolute_error: 0.0516\n",
            "Epoch 412/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0444 - val_mean_absolute_error: 0.0444\n",
            "Epoch 413/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
            "Epoch 414/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0539 - val_mean_absolute_error: 0.0539\n",
            "Epoch 415/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0382 - val_mean_absolute_error: 0.0382\n",
            "Epoch 416/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 417/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0399 - val_mean_absolute_error: 0.0399\n",
            "Epoch 418/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
            "Epoch 419/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
            "Epoch 420/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0849 - val_mean_absolute_error: 0.0849\n",
            "Epoch 421/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0752 - val_mean_absolute_error: 0.0752\n",
            "Epoch 422/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
            "Epoch 423/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0411 - val_mean_absolute_error: 0.0411\n",
            "Epoch 424/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0364 - val_mean_absolute_error: 0.0364\n",
            "Epoch 425/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 426/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0449 - val_mean_absolute_error: 0.0449\n",
            "Epoch 427/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0642 - val_mean_absolute_error: 0.0642\n",
            "Epoch 428/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
            "Epoch 429/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0457 - val_mean_absolute_error: 0.0457\n",
            "Epoch 430/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0679 - val_mean_absolute_error: 0.0679\n",
            "Epoch 431/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0627 - val_mean_absolute_error: 0.0627\n",
            "Epoch 432/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0602 - val_mean_absolute_error: 0.0602\n",
            "Epoch 433/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0275 - val_mean_absolute_error: 0.0275\n",
            "Epoch 434/1000\n",
            " - 2s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
            "Epoch 435/1000\n",
            " - 2s - loss: 0.0099 - mean_absolute_error: 0.0099 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
            "Epoch 436/1000\n",
            " - 2s - loss: 0.0141 - mean_absolute_error: 0.0141 - val_loss: 0.0329 - val_mean_absolute_error: 0.0329\n",
            "Epoch 437/1000\n",
            " - 2s - loss: 0.0138 - mean_absolute_error: 0.0138 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 438/1000\n",
            " - 1s - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0396 - val_mean_absolute_error: 0.0396\n",
            "Epoch 439/1000\n",
            " - 2s - loss: 0.0165 - mean_absolute_error: 0.0165 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
            "Epoch 440/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
            "Epoch 441/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0510 - val_mean_absolute_error: 0.0510\n",
            "Epoch 442/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
            "Epoch 443/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
            "Epoch 444/1000\n",
            " - 2s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
            "Epoch 445/1000\n",
            " - 2s - loss: 0.0123 - mean_absolute_error: 0.0123 - val_loss: 0.0502 - val_mean_absolute_error: 0.0502\n",
            "Epoch 446/1000\n",
            " - 2s - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
            "Epoch 447/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
            "Epoch 448/1000\n",
            " - 2s - loss: 0.0095 - mean_absolute_error: 0.0095 - val_loss: 0.0349 - val_mean_absolute_error: 0.0349\n",
            "Epoch 449/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0452 - val_mean_absolute_error: 0.0452\n",
            "Epoch 450/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
            "Epoch 451/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
            "Epoch 452/1000\n",
            " - 1s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
            "Epoch 453/1000\n",
            " - 1s - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
            "Epoch 454/1000\n",
            " - 1s - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
            "Epoch 455/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0864 - val_mean_absolute_error: 0.0864\n",
            "Epoch 456/1000\n",
            " - 1s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0768 - val_mean_absolute_error: 0.0768\n",
            "Epoch 457/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0635 - val_mean_absolute_error: 0.0635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 458/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
            "Epoch 459/1000\n",
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0329 - val_mean_absolute_error: 0.0329\n",
            "Epoch 460/1000\n",
            " - 2s - loss: 0.0113 - mean_absolute_error: 0.0113 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358\n",
            "Epoch 461/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
            "Epoch 462/1000\n",
            " - 2s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0427 - val_mean_absolute_error: 0.0427\n",
            "Epoch 463/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0498 - val_mean_absolute_error: 0.0498\n",
            "Epoch 464/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
            "Epoch 465/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0369 - val_mean_absolute_error: 0.0369\n",
            "Epoch 466/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0280 - val_mean_absolute_error: 0.0280\n",
            "Epoch 467/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187\n",
            "Epoch 468/1000\n",
            " - 1s - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
            "Epoch 469/1000\n",
            " - 1s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0364 - val_mean_absolute_error: 0.0364\n",
            "Epoch 470/1000\n",
            " - 2s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
            "Epoch 471/1000\n",
            " - 1s - loss: 0.0118 - mean_absolute_error: 0.0118 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
            "Epoch 472/1000\n",
            " - 1s - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
            "Epoch 473/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
            "Epoch 474/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0420 - val_mean_absolute_error: 0.0420\n",
            "Epoch 475/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0424 - val_mean_absolute_error: 0.0424\n",
            "Epoch 476/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
            "Epoch 477/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
            "Epoch 478/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
            "Epoch 479/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
            "Epoch 480/1000\n",
            " - 2s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
            "Epoch 481/1000\n",
            " - 2s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.1017 - val_mean_absolute_error: 0.1017\n",
            "Epoch 482/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0607 - val_mean_absolute_error: 0.0607\n",
            "Epoch 483/1000\n",
            " - 1s - loss: 0.0110 - mean_absolute_error: 0.0110 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
            "Epoch 484/1000\n",
            " - 1s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0638 - val_mean_absolute_error: 0.0638\n",
            "Epoch 485/1000\n",
            " - 1s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
            "Epoch 486/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
            "Epoch 487/1000\n",
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
            "Epoch 488/1000\n",
            " - 1s - loss: 0.0131 - mean_absolute_error: 0.0131 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
            "Epoch 489/1000\n",
            " - 2s - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
            "Epoch 490/1000\n",
            " - 2s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0470 - val_mean_absolute_error: 0.0470\n",
            "Epoch 491/1000\n",
            " - 2s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
            "Epoch 492/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0128 - val_mean_absolute_error: 0.0128\n",
            "Epoch 493/1000\n",
            " - 2s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0498 - val_mean_absolute_error: 0.0498\n",
            "Epoch 494/1000\n",
            " - 1s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
            "Epoch 495/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
            "Epoch 496/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 497/1000\n",
            " - 2s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
            "Epoch 498/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
            "Epoch 499/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0435 - val_mean_absolute_error: 0.0435\n",
            "Epoch 500/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
            "Epoch 501/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
            "Epoch 502/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
            "Epoch 503/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0357 - val_mean_absolute_error: 0.0357\n",
            "Epoch 504/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0434 - val_mean_absolute_error: 0.0434\n",
            "Epoch 505/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0351 - val_mean_absolute_error: 0.0351\n",
            "Epoch 506/1000\n",
            " - 2s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0282 - val_mean_absolute_error: 0.0282\n",
            "Epoch 507/1000\n",
            " - 2s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
            "Epoch 508/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
            "Epoch 509/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
            "Epoch 510/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "Epoch 511/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
            "Epoch 512/1000\n",
            " - 2s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0118 - val_mean_absolute_error: 0.0118\n",
            "Epoch 513/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
            "Epoch 514/1000\n",
            " - 2s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 515/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
            "Epoch 516/1000\n",
            " - 2s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
            "Epoch 517/1000\n",
            " - 1s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
            "Epoch 518/1000\n",
            " - 2s - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0782 - val_mean_absolute_error: 0.0782\n",
            "Epoch 519/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0564 - val_mean_absolute_error: 0.0564\n",
            "Epoch 520/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0510 - val_mean_absolute_error: 0.0510\n",
            "Epoch 521/1000\n",
            " - 2s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
            "Epoch 522/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0186 - val_mean_absolute_error: 0.0186\n",
            "Epoch 523/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
            "Epoch 524/1000\n",
            " - 2s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
            "Epoch 525/1000\n",
            " - 2s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
            "Epoch 526/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
            "Epoch 527/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0314 - val_mean_absolute_error: 0.0314\n",
            "Epoch 528/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "Epoch 529/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0323 - val_mean_absolute_error: 0.0323\n",
            "Epoch 530/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0578 - val_mean_absolute_error: 0.0578\n",
            "Epoch 531/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0396 - val_mean_absolute_error: 0.0396\n",
            "Epoch 532/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
            "Epoch 533/1000\n",
            " - 1s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0454 - val_mean_absolute_error: 0.0454\n",
            "Epoch 534/1000\n",
            " - 2s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "Epoch 535/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
            "Epoch 536/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0193 - val_mean_absolute_error: 0.0193\n",
            "Epoch 537/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
            "Epoch 538/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
            "Epoch 539/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362\n",
            "Epoch 540/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
            "Epoch 541/1000\n",
            " - 2s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
            "Epoch 542/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
            "Epoch 543/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
            "Epoch 544/1000\n",
            " - 2s - loss: 0.0106 - mean_absolute_error: 0.0106 - val_loss: 0.0397 - val_mean_absolute_error: 0.0397\n",
            "Epoch 545/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
            "Epoch 546/1000\n",
            " - 1s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
            "Epoch 547/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
            "Epoch 548/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
            "Epoch 549/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
            "Epoch 550/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
            "Epoch 551/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
            "Epoch 552/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
            "Epoch 553/1000\n",
            " - 2s - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
            "Epoch 554/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
            "Epoch 555/1000\n",
            " - 1s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0558 - val_mean_absolute_error: 0.0558\n",
            "Epoch 556/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0456 - val_mean_absolute_error: 0.0456\n",
            "Epoch 557/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
            "Epoch 558/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
            "Epoch 559/1000\n",
            " - 1s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
            "Epoch 560/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
            "Epoch 561/1000\n",
            " - 2s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
            "Epoch 562/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
            "Epoch 563/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0259 - val_mean_absolute_error: 0.0259\n",
            "Epoch 564/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
            "Epoch 565/1000\n",
            " - 2s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0186 - val_mean_absolute_error: 0.0186\n",
            "Epoch 566/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
            "Epoch 567/1000\n",
            " - 1s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0185 - val_mean_absolute_error: 0.0185\n",
            "Epoch 568/1000\n",
            " - 1s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0272 - val_mean_absolute_error: 0.0272\n",
            "Epoch 569/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0584 - val_mean_absolute_error: 0.0584\n",
            "Epoch 570/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 571/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 572/1000\n",
            " - 1s - loss: 0.0094 - mean_absolute_error: 0.0094 - val_loss: 0.0499 - val_mean_absolute_error: 0.0499\n",
            "Epoch 573/1000\n",
            " - 2s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0525 - val_mean_absolute_error: 0.0525\n",
            "Epoch 574/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
            "Epoch 575/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
            "Epoch 576/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0248 - val_mean_absolute_error: 0.0248\n",
            "Epoch 577/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0475 - val_mean_absolute_error: 0.0475\n",
            "Epoch 578/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
            "Epoch 579/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
            "Epoch 580/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0339 - val_mean_absolute_error: 0.0339\n",
            "Epoch 581/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
            "Epoch 582/1000\n",
            " - 1s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
            "Epoch 583/1000\n",
            " - 1s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
            "Epoch 584/1000\n",
            " - 1s - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0387 - val_mean_absolute_error: 0.0387\n",
            "Epoch 585/1000\n",
            " - 2s - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
            "Epoch 586/1000\n",
            " - 2s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
            "Epoch 587/1000\n",
            " - 2s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
            "Epoch 588/1000\n",
            " - 2s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
            "Epoch 589/1000\n",
            " - 2s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
            "Epoch 590/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.0458 - val_mean_absolute_error: 0.0458\n",
            "Epoch 591/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0580 - val_mean_absolute_error: 0.0580\n",
            "Epoch 592/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0509 - val_mean_absolute_error: 0.0509\n",
            "Epoch 593/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0415 - val_mean_absolute_error: 0.0415\n",
            "Epoch 594/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
            "Epoch 595/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0472 - val_mean_absolute_error: 0.0472\n",
            "Epoch 596/1000\n",
            " - 1s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
            "Epoch 597/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
            "Epoch 598/1000\n",
            " - 1s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0386 - val_mean_absolute_error: 0.0386\n",
            "Epoch 599/1000\n",
            " - 1s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0636 - val_mean_absolute_error: 0.0636\n",
            "Epoch 600/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
            "Epoch 601/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0421 - val_mean_absolute_error: 0.0421\n",
            "Epoch 602/1000\n",
            " - 1s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
            "Epoch 603/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
            "Epoch 604/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0389 - val_mean_absolute_error: 0.0389\n",
            "Epoch 605/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0439 - val_mean_absolute_error: 0.0439\n",
            "Epoch 606/1000\n",
            " - 1s - loss: 0.0091 - mean_absolute_error: 0.0091 - val_loss: 0.1060 - val_mean_absolute_error: 0.1060\n",
            "Epoch 607/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0595 - val_mean_absolute_error: 0.0595\n",
            "Epoch 608/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0266 - val_mean_absolute_error: 0.0266\n",
            "Epoch 609/1000\n",
            " - 2s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
            "Epoch 610/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0422 - val_mean_absolute_error: 0.0422\n",
            "Epoch 611/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0380 - val_mean_absolute_error: 0.0380\n",
            "Epoch 612/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0511 - val_mean_absolute_error: 0.0511\n",
            "Epoch 613/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0685 - val_mean_absolute_error: 0.0685\n",
            "Epoch 614/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0469 - val_mean_absolute_error: 0.0469\n",
            "Epoch 615/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
            "Epoch 616/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0820 - val_mean_absolute_error: 0.0820\n",
            "Epoch 617/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0360 - val_mean_absolute_error: 0.0360\n",
            "Epoch 618/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0414 - val_mean_absolute_error: 0.0414\n",
            "Epoch 619/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0412 - val_mean_absolute_error: 0.0412\n",
            "Epoch 620/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0321 - val_mean_absolute_error: 0.0321\n",
            "Epoch 621/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0236 - val_mean_absolute_error: 0.0236\n",
            "Epoch 622/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n",
            "Epoch 623/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
            "Epoch 624/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0586 - val_mean_absolute_error: 0.0586\n",
            "Epoch 625/1000\n",
            " - 1s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0281 - val_mean_absolute_error: 0.0281\n",
            "Epoch 626/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
            "Epoch 627/1000\n",
            " - 1s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
            "Epoch 628/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0242 - val_mean_absolute_error: 0.0242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 629/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0375 - val_mean_absolute_error: 0.0375\n",
            "Epoch 630/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
            "Epoch 631/1000\n",
            " - 1s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 632/1000\n",
            " - 1s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0118 - val_mean_absolute_error: 0.0118\n",
            "Epoch 633/1000\n",
            " - 1s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0665 - val_mean_absolute_error: 0.0665\n",
            "Epoch 634/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0509 - val_mean_absolute_error: 0.0509\n",
            "Epoch 635/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
            "Epoch 636/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0353 - val_mean_absolute_error: 0.0353\n",
            "Epoch 637/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
            "Epoch 638/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
            "Epoch 639/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0371 - val_mean_absolute_error: 0.0371\n",
            "Epoch 640/1000\n",
            " - 1s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
            "Epoch 641/1000\n",
            " - 2s - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
            "Epoch 642/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
            "Epoch 643/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
            "Epoch 644/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0662 - val_mean_absolute_error: 0.0662\n",
            "Epoch 645/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
            "Epoch 646/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0481 - val_mean_absolute_error: 0.0481\n",
            "Epoch 647/1000\n",
            " - 2s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0577 - val_mean_absolute_error: 0.0577\n",
            "Epoch 648/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0442 - val_mean_absolute_error: 0.0442\n",
            "Epoch 649/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0333 - val_mean_absolute_error: 0.0333\n",
            "Epoch 650/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
            "Epoch 651/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0812 - val_mean_absolute_error: 0.0812\n",
            "Epoch 652/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0516 - val_mean_absolute_error: 0.0516\n",
            "Epoch 653/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
            "Epoch 654/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
            "Epoch 655/1000\n",
            " - 2s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n",
            "Epoch 656/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0395 - val_mean_absolute_error: 0.0395\n",
            "Epoch 657/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0344 - val_mean_absolute_error: 0.0344\n",
            "Epoch 658/1000\n",
            " - 2s - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
            "Epoch 659/1000\n",
            " - 1s - loss: 0.0125 - mean_absolute_error: 0.0125 - val_loss: 0.0689 - val_mean_absolute_error: 0.0689\n",
            "Epoch 660/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0496 - val_mean_absolute_error: 0.0496\n",
            "Epoch 661/1000\n",
            " - 2s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
            "Epoch 662/1000\n",
            " - 2s - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
            "Epoch 663/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
            "Epoch 664/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0662 - val_mean_absolute_error: 0.0662\n",
            "Epoch 665/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0417 - val_mean_absolute_error: 0.0417\n",
            "Epoch 666/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465\n",
            "Epoch 667/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0421 - val_mean_absolute_error: 0.0421\n",
            "Epoch 668/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0361 - val_mean_absolute_error: 0.0361\n",
            "Epoch 669/1000\n",
            " - 2s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 670/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
            "Epoch 671/1000\n",
            " - 2s - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0598 - val_mean_absolute_error: 0.0598\n",
            "Epoch 672/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0544 - val_mean_absolute_error: 0.0544\n",
            "Epoch 673/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
            "Epoch 674/1000\n",
            " - 2s - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0246 - val_mean_absolute_error: 0.0246\n",
            "Epoch 675/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
            "Epoch 676/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0454 - val_mean_absolute_error: 0.0454\n",
            "Epoch 677/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0315 - val_mean_absolute_error: 0.0315\n",
            "Epoch 678/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0114 - val_mean_absolute_error: 0.0114\n",
            "Epoch 679/1000\n",
            " - 2s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
            "Epoch 680/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0441 - val_mean_absolute_error: 0.0441\n",
            "Epoch 681/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
            "Epoch 682/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
            "Epoch 683/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
            "Epoch 684/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
            "Epoch 685/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0360 - val_mean_absolute_error: 0.0360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 686/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
            "Epoch 687/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
            "Epoch 688/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
            "Epoch 689/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
            "Epoch 690/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
            "Epoch 691/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
            "Epoch 692/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0340 - val_mean_absolute_error: 0.0340\n",
            "Epoch 693/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0284 - val_mean_absolute_error: 0.0284\n",
            "Epoch 694/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0369 - val_mean_absolute_error: 0.0369\n",
            "Epoch 695/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0502 - val_mean_absolute_error: 0.0502\n",
            "Epoch 696/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
            "Epoch 697/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0519 - val_mean_absolute_error: 0.0519\n",
            "Epoch 698/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0240 - val_mean_absolute_error: 0.0240\n",
            "Epoch 699/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
            "Epoch 700/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
            "Epoch 701/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 702/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
            "Epoch 703/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0450 - val_mean_absolute_error: 0.0450\n",
            "Epoch 704/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
            "Epoch 705/1000\n",
            " - 2s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
            "Epoch 706/1000\n",
            " - 2s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0587 - val_mean_absolute_error: 0.0587\n",
            "Epoch 707/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
            "Epoch 708/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0326 - val_mean_absolute_error: 0.0326\n",
            "Epoch 709/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0450 - val_mean_absolute_error: 0.0450\n",
            "Epoch 710/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0253 - val_mean_absolute_error: 0.0253\n",
            "Epoch 711/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
            "Epoch 712/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
            "Epoch 713/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0512 - val_mean_absolute_error: 0.0512\n",
            "Epoch 714/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0512 - val_mean_absolute_error: 0.0512\n",
            "Epoch 715/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
            "Epoch 716/1000\n",
            " - 2s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
            "Epoch 717/1000\n",
            " - 1s - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0667 - val_mean_absolute_error: 0.0667\n",
            "Epoch 718/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0493 - val_mean_absolute_error: 0.0493\n",
            "Epoch 719/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0192 - val_mean_absolute_error: 0.0192\n",
            "Epoch 720/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
            "Epoch 721/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0243 - val_mean_absolute_error: 0.0243\n",
            "Epoch 722/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
            "Epoch 723/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0435 - val_mean_absolute_error: 0.0435\n",
            "Epoch 724/1000\n",
            " - 1s - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
            "Epoch 725/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
            "Epoch 726/1000\n",
            " - 2s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0769 - val_mean_absolute_error: 0.0769\n",
            "Epoch 727/1000\n",
            " - 2s - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
            "Epoch 728/1000\n",
            " - 2s - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
            "Epoch 729/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
            "Epoch 730/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
            "Epoch 731/1000\n",
            " - 1s - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0471 - val_mean_absolute_error: 0.0471\n",
            "Epoch 732/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
            "Epoch 733/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0261 - val_mean_absolute_error: 0.0261\n",
            "Epoch 734/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
            "Epoch 735/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0465 - val_mean_absolute_error: 0.0465\n",
            "Epoch 736/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0452 - val_mean_absolute_error: 0.0452\n",
            "Epoch 737/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0378 - val_mean_absolute_error: 0.0378\n",
            "Epoch 738/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0497 - val_mean_absolute_error: 0.0497\n",
            "Epoch 739/1000\n",
            " - 2s - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0526 - val_mean_absolute_error: 0.0526\n",
            "Epoch 740/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0365 - val_mean_absolute_error: 0.0365\n",
            "Epoch 741/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
            "Epoch 742/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 743/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
            "Epoch 744/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
            "Epoch 745/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0548 - val_mean_absolute_error: 0.0548\n",
            "Epoch 746/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0442 - val_mean_absolute_error: 0.0442\n",
            "Epoch 747/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
            "Epoch 748/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0414 - val_mean_absolute_error: 0.0414\n",
            "Epoch 749/1000\n",
            " - 2s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
            "Epoch 750/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
            "Epoch 751/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0430 - val_mean_absolute_error: 0.0430\n",
            "Epoch 752/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0239 - val_mean_absolute_error: 0.0239\n",
            "Epoch 753/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
            "Epoch 754/1000\n",
            " - 1s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0460 - val_mean_absolute_error: 0.0460\n",
            "Epoch 755/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
            "Epoch 756/1000\n",
            " - 1s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0792 - val_mean_absolute_error: 0.0792\n",
            "Epoch 757/1000\n",
            " - 1s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
            "Epoch 758/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0540 - val_mean_absolute_error: 0.0540\n",
            "Epoch 759/1000\n",
            " - 1s - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0486 - val_mean_absolute_error: 0.0486\n",
            "Epoch 760/1000\n",
            " - 1s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0688 - val_mean_absolute_error: 0.0688\n",
            "Epoch 761/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
            "Epoch 762/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0514 - val_mean_absolute_error: 0.0514\n",
            "Epoch 763/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0377 - val_mean_absolute_error: 0.0377\n",
            "Epoch 764/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
            "Epoch 765/1000\n",
            " - 2s - loss: 0.0100 - mean_absolute_error: 0.0100 - val_loss: 0.1005 - val_mean_absolute_error: 0.1005\n",
            "Epoch 766/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0408 - val_mean_absolute_error: 0.0408\n",
            "Epoch 767/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
            "Epoch 768/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
            "Epoch 769/1000\n",
            " - 2s - loss: 0.0109 - mean_absolute_error: 0.0109 - val_loss: 0.0545 - val_mean_absolute_error: 0.0545\n",
            "Epoch 770/1000\n",
            " - 2s - loss: 0.0127 - mean_absolute_error: 0.0127 - val_loss: 0.0839 - val_mean_absolute_error: 0.0839\n",
            "Epoch 771/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0633 - val_mean_absolute_error: 0.0633\n",
            "Epoch 772/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0562 - val_mean_absolute_error: 0.0562\n",
            "Epoch 773/1000\n",
            " - 1s - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0549 - val_mean_absolute_error: 0.0549\n",
            "Epoch 774/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
            "Epoch 775/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
            "Epoch 776/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
            "Epoch 777/1000\n",
            " - 2s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n",
            "Epoch 778/1000\n",
            " - 2s - loss: 0.0130 - mean_absolute_error: 0.0130 - val_loss: 0.1077 - val_mean_absolute_error: 0.1077\n",
            "Epoch 779/1000\n",
            " - 2s - loss: 0.0119 - mean_absolute_error: 0.0119 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
            "Epoch 780/1000\n",
            " - 1s - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0611 - val_mean_absolute_error: 0.0611\n",
            "Epoch 781/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0488 - val_mean_absolute_error: 0.0488\n",
            "Epoch 782/1000\n",
            " - 2s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0508 - val_mean_absolute_error: 0.0508\n",
            "Epoch 783/1000\n",
            " - 2s - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0932 - val_mean_absolute_error: 0.0932\n",
            "Epoch 784/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0636 - val_mean_absolute_error: 0.0636\n",
            "Epoch 785/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
            "Epoch 786/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
            "Epoch 787/1000\n",
            " - 1s - loss: 0.0097 - mean_absolute_error: 0.0097 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
            "Epoch 788/1000\n",
            " - 1s - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.0548 - val_mean_absolute_error: 0.0548\n",
            "Epoch 789/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0620 - val_mean_absolute_error: 0.0620\n",
            "Epoch 790/1000\n",
            " - 2s - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0460 - val_mean_absolute_error: 0.0460\n",
            "Epoch 791/1000\n",
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
            "Epoch 792/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0725 - val_mean_absolute_error: 0.0725\n",
            "Epoch 793/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0561 - val_mean_absolute_error: 0.0561\n",
            "Epoch 794/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
            "Epoch 795/1000\n",
            " - 1s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
            "Epoch 796/1000\n",
            " - 2s - loss: 0.0108 - mean_absolute_error: 0.0108 - val_loss: 0.0834 - val_mean_absolute_error: 0.0834\n",
            "Epoch 797/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0403 - val_mean_absolute_error: 0.0403\n",
            "Epoch 798/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0238 - val_mean_absolute_error: 0.0238\n",
            "Epoch 799/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 800/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0609 - val_mean_absolute_error: 0.0609\n",
            "Epoch 801/1000\n",
            " - 2s - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0478 - val_mean_absolute_error: 0.0478\n",
            "Epoch 802/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
            "Epoch 803/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
            "Epoch 804/1000\n",
            " - 1s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0455 - val_mean_absolute_error: 0.0455\n",
            "Epoch 805/1000\n",
            " - 1s - loss: 0.0033 - mean_absolute_error: 0.0033 - val_loss: 0.0357 - val_mean_absolute_error: 0.0357\n",
            "Epoch 806/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
            "Epoch 807/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0870 - val_mean_absolute_error: 0.0870\n",
            "Epoch 808/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
            "Epoch 809/1000\n",
            " - 2s - loss: 0.0039 - mean_absolute_error: 0.0039 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
            "Epoch 810/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0354 - val_mean_absolute_error: 0.0354\n",
            "Epoch 811/1000\n",
            " - 1s - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0692 - val_mean_absolute_error: 0.0692\n",
            "Epoch 812/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
            "Epoch 813/1000\n",
            " - 2s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0426 - val_mean_absolute_error: 0.0426\n",
            "Epoch 814/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0392 - val_mean_absolute_error: 0.0392\n",
            "Epoch 815/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
            "Epoch 816/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0756 - val_mean_absolute_error: 0.0756\n",
            "Epoch 817/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0596 - val_mean_absolute_error: 0.0596\n",
            "Epoch 818/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
            "Epoch 819/1000\n",
            " - 1s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0395 - val_mean_absolute_error: 0.0395\n",
            "Epoch 820/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0800 - val_mean_absolute_error: 0.0800\n",
            "Epoch 821/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0714 - val_mean_absolute_error: 0.0714\n",
            "Epoch 822/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 823/1000\n",
            " - 1s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
            "Epoch 824/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0698 - val_mean_absolute_error: 0.0698\n",
            "Epoch 825/1000\n",
            " - 2s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0523 - val_mean_absolute_error: 0.0523\n",
            "Epoch 826/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0435 - val_mean_absolute_error: 0.0435\n",
            "Epoch 827/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0359 - val_mean_absolute_error: 0.0359\n",
            "Epoch 828/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0753 - val_mean_absolute_error: 0.0753\n",
            "Epoch 829/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0686 - val_mean_absolute_error: 0.0686\n",
            "Epoch 830/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0579 - val_mean_absolute_error: 0.0579\n",
            "Epoch 831/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
            "Epoch 832/1000\n",
            " - 1s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0913 - val_mean_absolute_error: 0.0913\n",
            "Epoch 833/1000\n",
            " - 1s - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0755 - val_mean_absolute_error: 0.0755\n",
            "Epoch 834/1000\n",
            " - 1s - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.0742 - val_mean_absolute_error: 0.0742\n",
            "Epoch 835/1000\n",
            " - 1s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
            "Epoch 836/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0466 - val_mean_absolute_error: 0.0466\n",
            "Epoch 837/1000\n",
            " - 2s - loss: 0.0089 - mean_absolute_error: 0.0089 - val_loss: 0.0953 - val_mean_absolute_error: 0.0953\n",
            "Epoch 838/1000\n",
            " - 1s - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0753 - val_mean_absolute_error: 0.0753\n",
            "Epoch 839/1000\n",
            " - 1s - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
            "Epoch 840/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0528 - val_mean_absolute_error: 0.0528\n",
            "Epoch 841/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0432 - val_mean_absolute_error: 0.0432\n",
            "Epoch 842/1000\n",
            " - 1s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.1001 - val_mean_absolute_error: 0.1001\n",
            "Epoch 843/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0757 - val_mean_absolute_error: 0.0757\n",
            "Epoch 844/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
            "Epoch 845/1000\n",
            " - 2s - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
            "Epoch 846/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
            "Epoch 847/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0748 - val_mean_absolute_error: 0.0748\n",
            "Epoch 848/1000\n",
            " - 2s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0480 - val_mean_absolute_error: 0.0480\n",
            "Epoch 849/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0379 - val_mean_absolute_error: 0.0379\n",
            "Epoch 850/1000\n",
            " - 2s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
            "Epoch 851/1000\n",
            " - 1s - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0976 - val_mean_absolute_error: 0.0976\n",
            "Epoch 852/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0778 - val_mean_absolute_error: 0.0778\n",
            "Epoch 853/1000\n",
            " - 1s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0577 - val_mean_absolute_error: 0.0577\n",
            "Epoch 854/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362\n",
            "Epoch 855/1000\n",
            " - 2s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.1019 - val_mean_absolute_error: 0.1019\n",
            "Epoch 856/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0869 - val_mean_absolute_error: 0.0869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 857/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 858/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0697 - val_mean_absolute_error: 0.0697\n",
            "Epoch 859/1000\n",
            " - 2s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0484 - val_mean_absolute_error: 0.0484\n",
            "Epoch 860/1000\n",
            " - 1s - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0948 - val_mean_absolute_error: 0.0948\n",
            "Epoch 861/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0968 - val_mean_absolute_error: 0.0968\n",
            "Epoch 862/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0876 - val_mean_absolute_error: 0.0876\n",
            "Epoch 863/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0567 - val_mean_absolute_error: 0.0567\n",
            "Epoch 864/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0604 - val_mean_absolute_error: 0.0604\n",
            "Epoch 865/1000\n",
            " - 2s - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0411 - val_mean_absolute_error: 0.0411\n",
            "Epoch 866/1000\n",
            " - 2s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0920 - val_mean_absolute_error: 0.0920\n",
            "Epoch 867/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0758 - val_mean_absolute_error: 0.0758\n",
            "Epoch 868/1000\n",
            " - 2s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0650 - val_mean_absolute_error: 0.0650\n",
            "Epoch 869/1000\n",
            " - 2s - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0838 - val_mean_absolute_error: 0.0838\n",
            "Epoch 870/1000\n",
            " - 2s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0592 - val_mean_absolute_error: 0.0592\n",
            "Epoch 871/1000\n",
            " - 2s - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0546 - val_mean_absolute_error: 0.0546\n",
            "Epoch 872/1000\n",
            " - 1s - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0510 - val_mean_absolute_error: 0.0510\n",
            "Epoch 873/1000\n",
            " - 1s - loss: 0.0033 - mean_absolute_error: 0.0033 - val_loss: 0.0626 - val_mean_absolute_error: 0.0626\n",
            "Epoch 874/1000\n",
            " - 2s - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0658 - val_mean_absolute_error: 0.0658\n",
            "Epoch 875/1000\n",
            " - 2s - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0764 - val_mean_absolute_error: 0.0764\n",
            "Epoch 876/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0817 - val_mean_absolute_error: 0.0817\n",
            "Epoch 877/1000\n",
            " - 2s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
            "Epoch 878/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0687 - val_mean_absolute_error: 0.0687\n",
            "Epoch 879/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0561 - val_mean_absolute_error: 0.0561\n",
            "Epoch 880/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
            "Epoch 881/1000\n",
            " - 1s - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.1237 - val_mean_absolute_error: 0.1237\n",
            "Epoch 882/1000\n",
            " - 1s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.1082 - val_mean_absolute_error: 0.1082\n",
            "Epoch 883/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0552 - val_mean_absolute_error: 0.0552\n",
            "Epoch 884/1000\n",
            " - 1s - loss: 0.0043 - mean_absolute_error: 0.0043 - val_loss: 0.0550 - val_mean_absolute_error: 0.0550\n",
            "Epoch 885/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0898 - val_mean_absolute_error: 0.0898\n",
            "Epoch 886/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1010 - val_mean_absolute_error: 0.1010\n",
            "Epoch 887/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.1001 - val_mean_absolute_error: 0.1001\n",
            "Epoch 888/1000\n",
            " - 2s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0756 - val_mean_absolute_error: 0.0756\n",
            "Epoch 889/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0519 - val_mean_absolute_error: 0.0519\n",
            "Epoch 890/1000\n",
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0694 - val_mean_absolute_error: 0.0694\n",
            "Epoch 891/1000\n",
            " - 2s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0699 - val_mean_absolute_error: 0.0699\n",
            "Epoch 892/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.1030 - val_mean_absolute_error: 0.1030\n",
            "Epoch 893/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.1178 - val_mean_absolute_error: 0.1178\n",
            "Epoch 894/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
            "Epoch 895/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0537 - val_mean_absolute_error: 0.0537\n",
            "Epoch 896/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0689 - val_mean_absolute_error: 0.0689\n",
            "Epoch 897/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0797 - val_mean_absolute_error: 0.0797\n",
            "Epoch 898/1000\n",
            " - 1s - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
            "Epoch 899/1000\n",
            " - 1s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0729 - val_mean_absolute_error: 0.0729\n",
            "Epoch 900/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0883 - val_mean_absolute_error: 0.0883\n",
            "Epoch 901/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0614 - val_mean_absolute_error: 0.0614\n",
            "Epoch 902/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0675 - val_mean_absolute_error: 0.0675\n",
            "Epoch 903/1000\n",
            " - 1s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0616 - val_mean_absolute_error: 0.0616\n",
            "Epoch 904/1000\n",
            " - 1s - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0720 - val_mean_absolute_error: 0.0720\n",
            "Epoch 905/1000\n",
            " - 1s - loss: 0.0034 - mean_absolute_error: 0.0034 - val_loss: 0.0868 - val_mean_absolute_error: 0.0868\n",
            "Epoch 906/1000\n",
            " - 1s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0622 - val_mean_absolute_error: 0.0622\n",
            "Epoch 907/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0739 - val_mean_absolute_error: 0.0739\n",
            "Epoch 908/1000\n",
            " - 1s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0818 - val_mean_absolute_error: 0.0818\n",
            "Epoch 909/1000\n",
            " - 1s - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0589 - val_mean_absolute_error: 0.0589\n",
            "Epoch 910/1000\n",
            " - 1s - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
            "Epoch 911/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0726 - val_mean_absolute_error: 0.0726\n",
            "Epoch 912/1000\n",
            " - 1s - loss: 0.0038 - mean_absolute_error: 0.0038 - val_loss: 0.0752 - val_mean_absolute_error: 0.0752\n",
            "Epoch 913/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0794 - val_mean_absolute_error: 0.0794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 914/1000\n",
            " - 1s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0605 - val_mean_absolute_error: 0.0605\n",
            "Epoch 915/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0430 - val_mean_absolute_error: 0.0430\n",
            "Epoch 916/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
            "Epoch 917/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.1085 - val_mean_absolute_error: 0.1085\n",
            "Epoch 918/1000\n",
            " - 2s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0766 - val_mean_absolute_error: 0.0766\n",
            "Epoch 919/1000\n",
            " - 1s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0553 - val_mean_absolute_error: 0.0553\n",
            "Epoch 920/1000\n",
            " - 2s - loss: 0.0116 - mean_absolute_error: 0.0116 - val_loss: 0.1361 - val_mean_absolute_error: 0.1361\n",
            "Epoch 921/1000\n",
            " - 2s - loss: 0.0111 - mean_absolute_error: 0.0111 - val_loss: 0.1006 - val_mean_absolute_error: 0.1006\n",
            "Epoch 922/1000\n",
            " - 1s - loss: 0.0144 - mean_absolute_error: 0.0144 - val_loss: 0.0966 - val_mean_absolute_error: 0.0966\n",
            "Epoch 923/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0719 - val_mean_absolute_error: 0.0719\n",
            "Epoch 924/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0644 - val_mean_absolute_error: 0.0644\n",
            "Epoch 925/1000\n",
            " - 2s - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
            "Epoch 926/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.1034 - val_mean_absolute_error: 0.1034\n",
            "Epoch 927/1000\n",
            " - 1s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0785 - val_mean_absolute_error: 0.0785\n",
            "Epoch 928/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0572 - val_mean_absolute_error: 0.0572\n",
            "Epoch 929/1000\n",
            " - 1s - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0955 - val_mean_absolute_error: 0.0955\n",
            "Epoch 930/1000\n",
            " - 1s - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0904 - val_mean_absolute_error: 0.0904\n",
            "Epoch 931/1000\n",
            " - 1s - loss: 0.0098 - mean_absolute_error: 0.0098 - val_loss: 0.1076 - val_mean_absolute_error: 0.1076\n",
            "Epoch 932/1000\n",
            " - 2s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0940 - val_mean_absolute_error: 0.0940\n",
            "Epoch 933/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0581 - val_mean_absolute_error: 0.0581\n",
            "Epoch 934/1000\n",
            " - 1s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0795 - val_mean_absolute_error: 0.0795\n",
            "Epoch 935/1000\n",
            " - 1s - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.0661 - val_mean_absolute_error: 0.0661\n",
            "Epoch 936/1000\n",
            " - 1s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0700 - val_mean_absolute_error: 0.0700\n",
            "Epoch 937/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0992 - val_mean_absolute_error: 0.0992\n",
            "Epoch 938/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0977 - val_mean_absolute_error: 0.0977\n",
            "Epoch 939/1000\n",
            " - 1s - loss: 0.0049 - mean_absolute_error: 0.0049 - val_loss: 0.0793 - val_mean_absolute_error: 0.0793\n",
            "Epoch 940/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0734 - val_mean_absolute_error: 0.0734\n",
            "Epoch 941/1000\n",
            " - 1s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0654 - val_mean_absolute_error: 0.0654\n",
            "Epoch 942/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
            "Epoch 943/1000\n",
            " - 2s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0809 - val_mean_absolute_error: 0.0809\n",
            "Epoch 944/1000\n",
            " - 2s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0890 - val_mean_absolute_error: 0.0890\n",
            "Epoch 945/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.1051 - val_mean_absolute_error: 0.1051\n",
            "Epoch 946/1000\n",
            " - 2s - loss: 0.0037 - mean_absolute_error: 0.0037 - val_loss: 0.0787 - val_mean_absolute_error: 0.0787\n",
            "Epoch 947/1000\n",
            " - 1s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
            "Epoch 948/1000\n",
            " - 1s - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0955 - val_mean_absolute_error: 0.0955\n",
            "Epoch 949/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0947 - val_mean_absolute_error: 0.0947\n",
            "Epoch 950/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.0591 - val_mean_absolute_error: 0.0591\n",
            "Epoch 951/1000\n",
            " - 2s - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0912 - val_mean_absolute_error: 0.0912\n",
            "Epoch 952/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
            "Epoch 953/1000\n",
            " - 1s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
            "Epoch 954/1000\n",
            " - 2s - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.1032 - val_mean_absolute_error: 0.1032\n",
            "Epoch 955/1000\n",
            " - 2s - loss: 0.0048 - mean_absolute_error: 0.0048 - val_loss: 0.1110 - val_mean_absolute_error: 0.1110\n",
            "Epoch 956/1000\n",
            " - 2s - loss: 0.0044 - mean_absolute_error: 0.0044 - val_loss: 0.0746 - val_mean_absolute_error: 0.0746\n",
            "Epoch 957/1000\n",
            " - 2s - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0774 - val_mean_absolute_error: 0.0774\n",
            "Epoch 958/1000\n",
            " - 2s - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0750 - val_mean_absolute_error: 0.0750\n",
            "Epoch 959/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0763 - val_mean_absolute_error: 0.0763\n",
            "Epoch 960/1000\n",
            " - 1s - loss: 0.0042 - mean_absolute_error: 0.0042 - val_loss: 0.0724 - val_mean_absolute_error: 0.0724\n",
            "Epoch 961/1000\n",
            " - 2s - loss: 0.0035 - mean_absolute_error: 0.0035 - val_loss: 0.0882 - val_mean_absolute_error: 0.0882\n",
            "Epoch 962/1000\n",
            " - 1s - loss: 0.0036 - mean_absolute_error: 0.0036 - val_loss: 0.0630 - val_mean_absolute_error: 0.0630\n",
            "Epoch 963/1000\n",
            " - 1s - loss: 0.0047 - mean_absolute_error: 0.0047 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
            "Epoch 964/1000\n",
            " - 1s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.1079 - val_mean_absolute_error: 0.1079\n",
            "Epoch 965/1000\n",
            " - 2s - loss: 0.0040 - mean_absolute_error: 0.0040 - val_loss: 0.0916 - val_mean_absolute_error: 0.0916\n",
            "Epoch 966/1000\n",
            " - 2s - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0753 - val_mean_absolute_error: 0.0753\n",
            "Epoch 967/1000\n",
            " - 2s - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0892 - val_mean_absolute_error: 0.0892\n",
            "Epoch 968/1000\n",
            " - 2s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0810 - val_mean_absolute_error: 0.0810\n",
            "Epoch 969/1000\n",
            " - 2s - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0585 - val_mean_absolute_error: 0.0585\n",
            "Epoch 970/1000\n",
            " - 1s - loss: 0.0105 - mean_absolute_error: 0.0105 - val_loss: 0.1319 - val_mean_absolute_error: 0.1319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 971/1000\n",
            " - 1s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0759 - val_mean_absolute_error: 0.0759\n",
            "Epoch 972/1000\n",
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0789 - val_mean_absolute_error: 0.0789\n",
            "Epoch 973/1000\n",
            " - 1s - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
            "Epoch 974/1000\n",
            " - 2s - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.1401 - val_mean_absolute_error: 0.1401\n",
            "Epoch 975/1000\n",
            " - 1s - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0841 - val_mean_absolute_error: 0.0841\n",
            "Epoch 976/1000\n",
            " - 1s - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0845 - val_mean_absolute_error: 0.0845\n",
            "Epoch 977/1000\n",
            " - 2s - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0623 - val_mean_absolute_error: 0.0623\n",
            "Epoch 978/1000\n",
            " - 2s - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0840 - val_mean_absolute_error: 0.0840\n",
            "Epoch 979/1000\n",
            " - 1s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.1170 - val_mean_absolute_error: 0.1170\n",
            "Epoch 980/1000\n",
            " - 1s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.1083 - val_mean_absolute_error: 0.1083\n",
            "Epoch 981/1000\n",
            " - 2s - loss: 0.0041 - mean_absolute_error: 0.0041 - val_loss: 0.0839 - val_mean_absolute_error: 0.0839\n",
            "Epoch 982/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0533 - val_mean_absolute_error: 0.0533\n",
            "Epoch 983/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0859 - val_mean_absolute_error: 0.0859\n",
            "Epoch 984/1000\n",
            " - 1s - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0716 - val_mean_absolute_error: 0.0716\n",
            "Epoch 985/1000\n",
            " - 1s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0881 - val_mean_absolute_error: 0.0881\n",
            "Epoch 986/1000\n",
            " - 1s - loss: 0.0045 - mean_absolute_error: 0.0045 - val_loss: 0.0662 - val_mean_absolute_error: 0.0662\n",
            "Epoch 987/1000\n",
            " - 1s - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1110 - val_mean_absolute_error: 0.1110\n",
            "Epoch 988/1000\n",
            " - 2s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.1125 - val_mean_absolute_error: 0.1125\n",
            "Epoch 989/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0872 - val_mean_absolute_error: 0.0872\n",
            "Epoch 990/1000\n",
            " - 2s - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0767 - val_mean_absolute_error: 0.0767\n",
            "Epoch 991/1000\n",
            " - 2s - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0687 - val_mean_absolute_error: 0.0687\n",
            "Epoch 992/1000\n",
            " - 2s - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.1226 - val_mean_absolute_error: 0.1226\n",
            "Epoch 993/1000\n",
            " - 1s - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.1016 - val_mean_absolute_error: 0.1016\n",
            "Epoch 994/1000\n",
            " - 1s - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0905 - val_mean_absolute_error: 0.0905\n",
            "Epoch 995/1000\n",
            " - 1s - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0762 - val_mean_absolute_error: 0.0762\n",
            "Epoch 996/1000\n",
            " - 1s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
            "Epoch 997/1000\n",
            " - 1s - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.1099 - val_mean_absolute_error: 0.1099\n",
            "Epoch 998/1000\n",
            " - 2s - loss: 0.0107 - mean_absolute_error: 0.0107 - val_loss: 0.1058 - val_mean_absolute_error: 0.1058\n",
            "Epoch 999/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " - 2s - loss: 0.0050 - mean_absolute_error: 0.0050 - val_loss: 0.1045 - val_mean_absolute_error: 0.1045\n",
            "Epoch 1000/1000\n",
            " - 2s - loss: 0.0046 - mean_absolute_error: 0.0046 - val_loss: 0.0991 - val_mean_absolute_error: 0.0991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\newghFOhDRyfbg0JcpdwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5b2926b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "s_zQaZQQJBSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd1be4a7-7f57-4821-f75b-7060c0b6d7f8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test RMSE: 3963.160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fqmnx2uNXqUT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}